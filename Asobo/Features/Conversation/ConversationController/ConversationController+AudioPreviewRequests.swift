import Foundation
import AVFoundation
import Speech
import Services
import Domain
import DataStores

extension ConversationController {
    // MARK: - Turn helpers (shared across extensions)
    func advanceTurnId() -> Int {
        currentTurnId += 1
        playbackTurnId = nil
        return currentTurnId
    }

    func markListeningTurn() {
        listeningTurnId = currentTurnId
        silenceTimer?.invalidate()
        silenceTimer = nil
    }

    func isCurrentTurn(_ turnId: Int) -> Bool {
        turnId == currentTurnId
    }

    // MARK: - Local transcription helper (for history)
    /// ãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§æ–‡å­—èµ·ã“ã—ï¼ˆä¼šè©±å±¥æ­´ç”¨ï¼‰ã€‚å¤±æ•—æ™‚ã¯ nil ã‚’è¿”ã™ã€‚
    nonisolated static func transcribeUserAudio(wavData: Data) async -> String? {
        // âœ… ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STTãŒä¸å®‰å®šãªç’°å¢ƒã§ã¯æ—©æœŸã«è«¦ã‚ã¦ã‚¨ãƒ©ãƒ¼ã‚’æŠ‘åˆ¶
        let authStatus = SFSpeechRecognizer.authorizationStatus()
        guard authStatus == .authorized,
              let recognizer = SFSpeechRecognizer(locale: Locale(identifier: "ja-JP")),
              recognizer.isAvailable else { return nil }

        let tmpURL = FileManager.default.temporaryDirectory.appendingPathComponent("user_audio_\(UUID().uuidString).wav")
        do {
            try wavData.write(to: tmpURL)
        } catch {
            print("âš ï¸ UserAudioTranscribe: write failed - \(error)")
            return nil
        }

        return await withCheckedContinuation { continuation in
            var didFinish = false
            func finish(_ text: String?) {
                if didFinish { return }
                didFinish = true
                continuation.resume(returning: text)
                try? FileManager.default.removeItem(at: tmpURL)
            }

            let request = SFSpeechURLRecognitionRequest(url: tmpURL)
            var task: SFSpeechRecognitionTask?
            task = recognizer.recognitionTask(with: request) { result, error in
                if let result = result, result.isFinal {
                    finish(result.bestTranscription.formattedString)
                    task?.cancel()
                } else if let error = error {
                    // kAFAssistantErrorDomain 1101 ã¯ã€Œãƒ­ãƒ¼ã‚«ãƒ«èªè­˜ä¸å¯ã€ã§é »ç™ºã™ã‚‹ãŸã‚é™ã‹ã«ç„¡è¦–
                    let nsError = error as NSError
                    if !(nsError.domain == "kAFAssistantErrorDomain" && nsError.code == 1101) {
                        print("âš ï¸ UserAudioTranscribe: recognition error - \(error)")
                    }
                    finish(nil)
                }
            }
        }
    }

    // MARK: - Audio-preview requests
    func sendTextPreviewRequest(userText: String) async {
        guard let client = audioPreviewClient else {
            await MainActor.run { self.errorMessage = "éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“" }
            return
        }

        let trimmed = userText.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !trimmed.isEmpty else { return }

        // âœ… ã“ã®ã‚¿ãƒ¼ãƒ³ã®ã€Œè©±è€…ï¼ˆå­ï¼‰ã€ãƒ¡ã‚¿æƒ…å ±ã¯ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹æ™‚ç‚¹ã§ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã™ã‚‹
        // ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹å¾…ã¡ã®é–“ã«UIã®â€œæŠ¼ä¸‹â€ãŒé›¢ã‚Œã¦ã‚‚ã€ä¼šè©±ã¨ã—ã¦ã¯æŠ¼ä¸‹ä¸­ã«è©±ã—ã¦ã„ãŸã“ã¨ãŒã‚ã‚‹ãŸã‚ï¼‰
        let speakerChildIdForThisTurn = self.speakerChildIdOverride
        let speakerChildNameForThisTurn = self.speakerChildNameOverride

        await MainActor.run {
            // âœ… å±¥æ­´ã«ç©ã‚€ã®ã¨åŒã˜ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆã‚’UIã¸å…¬é–‹ï¼ˆHomeã®ãƒ¢ãƒ‹ã‚¿ãƒ¼è¡¨ç¤ºç”¨ï¼‰
            self.lastCommittedUserText = trimmed
            // æ–°ã—ã„è¿”ç­”ã‚’é–‹å§‹ã™ã‚‹ã®ã§å‰ã®è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
            self.aiResponseText = ""
            self.turnMetrics.requestStart = Date()
            self.logTurnStageTiming(event: "request", at: self.turnMetrics.requestStart!)
        }

        let turnId = advanceTurnId()
        ignoreIncomingAIChunks = false

        // AIãŒè€ƒãˆå§‹ã‚ã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ç›¸æ§Œã‚’æ‰“ã¤
        await MainActor.run {
            self.isThinking = true
            self.playRandomFiller()
            self.player.prepareForNextStream()
        }

        let tStart = Date()
        print("â±ï¸ ConversationController: sendTextPreviewRequest start - textLen=\(trimmed.count)")
        print("ğŸ§© ConversationController: systemPrompt audioMissingBoost=\(audioMissingConsecutiveCount > 0) (consecutive=\(audioMissingConsecutiveCount))")
        let promptHead = String(currentSystemPrompt.prefix(140)).replacingOccurrences(of: "\n", with: "\\n")
        print("ğŸ§© ConversationController: systemPrompt head(140)=\(promptHead)")

        do {
            let result = try await client.streamResponseText(
                userText: trimmed,
                systemPrompt: currentSystemPrompt,
                history: conversationHistory,
                userMessagePrefix: audioPreviewUserMessagePrefix,
                onText: { [weak self] delta in
                    guard let self else { return }
                    Task { @MainActor in
                        guard !self.ignoreIncomingAIChunks, self.isCurrentTurn(turnId) else { return }
                        if self.turnMetrics.firstText == nil {
                            self.turnMetrics.firstText = Date()
                            self.logTurnStageTiming(event: "firstText", at: self.turnMetrics.firstText!)
                        }
                        let clean = self.sanitizeAIText(delta)
                        if clean.isEmpty { return }
                        print("ğŸŸ¦ onText delta (clean):", clean)
                        self.aiResponseText += clean
                    }
                },
                onAudioChunk: { [weak self] chunk in
                    guard let self else { return }
                    Task { @MainActor in
                        guard !self.ignoreIncomingAIChunks, self.isCurrentTurn(turnId) else { return }
                        print("ğŸ”Š onAudioChunk bytes:", chunk.count)
                        self.playbackTurnId = turnId
                        self.turnState = .speaking
                        // ç›¸æ§ŒãŒé³´ã£ã¦ã„ã¦ã‚‚å¼·åˆ¶åœæ­¢ã›ãšè‡ªç„¶ã«çµ‚ã‚ã‚‰ã›ã‚‹
                        if self.isFillerPlaying {
                            self.isFillerPlaying = false
                        }
                        self.handleFirstAudioChunk(for: turnId)
                        self.player.resumeIfNeeded()
                        // å‡ºåŠ›ã¯pcm16æŒ‡å®šãªã®ã§ãã®ã¾ã¾å†ç”Ÿ
                        self.player.playChunk(chunk)
                    }
                },
                onFirstByte: { [weak self] firstByte in
                    guard let self else { return }
                    Task { @MainActor in
                        guard !self.ignoreIncomingAIChunks, self.isCurrentTurn(turnId) else { return }
                        self.turnMetrics.firstByte = firstByte
                        self.logTurnStageTiming(event: "firstByte", at: firstByte)
                    }
                }
            )
            let tEnd = Date()
            print("â±ï¸ ConversationController: sendTextPreviewRequest completed in \(String(format: "%.2f", tEnd.timeIntervalSince(tStart)))s, finalText.count=\(result.text.count), finalText=\"\(result.text)\", audioMissing=\(result.audioMissing)")
            audioMissingConsecutiveCount = result.audioMissing ? min(audioMissingConsecutiveCount + 1, 3) : 0
            let cleanFinal = self.sanitizeAIText(result.text)
            guard self.isCurrentTurn(turnId) else { return }
            turnMetrics.streamComplete = tEnd
            logTurnStageTiming(event: "streamComplete", at: tEnd)
            logTurnLatencySummary(context: "stream complete (text)")

            await MainActor.run {
                // å¹ãå‡ºã—ç”¨ã«æœ€çµ‚ãƒ†ã‚­ã‚¹ãƒˆã‚’UIã¸åæ˜ 
                self.aiResponseText = cleanFinal
                if !result.audioMissing {
                    if self.isHandsFreeMode && self.isRecording && self.turnState != .speaking {
                        self.resumeListening()
                    } else if self.turnState != .speaking {
                        self.turnState = .waitingUser
                        self.startWaitingForResponse()
                    }
                } else {
                    print("ğŸº ConversationController: text-only response -> fallback TTS will run")
                }
            }

            if result.audioMissing {
                await self.playFallbackTTS(text: cleanFinal, turnId: turnId)
            }

            // Firebaseä¿å­˜
            if let userId = currentUserId, let childId = currentChildId, let sessionId = currentSessionId {
                let speakerChildId = speakerChildIdForThisTurn
                let speakerChildName = speakerChildNameForThisTurn
                let userTurn = FirebaseTurn(role: .child, text: trimmed, timestamp: Date())
                let aiTurn = FirebaseTurn(role: .ai, text: cleanFinal, timestamp: Date())
                print("ğŸ—‚ï¸ ConversationController: append inMemoryTurns (user:'\(userTurn.text ?? "nil")', ai:'\(aiTurn.text ?? "nil")')")
                inMemoryTurns.append(contentsOf: [userTurn, aiTurn])
                // âœ… å±¥æ­´ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ç©ã‚€ï¼ˆç›´è¿‘ã®æ–‡è„ˆã¨ã—ã¦ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹APIã¸æ¸¡ã™ï¼‰
                conversationHistory.append(HistoryItem(role: "user", text: trimmed))
                conversationHistory.append(HistoryItem(role: "assistant", text: cleanFinal))
                // å±¥æ­´ãŒé•·ããªã‚Šã™ããªã„ã‚ˆã†ã«6ã‚¿ãƒ¼ãƒ³åˆ†ï¼ˆ12ã‚¨ãƒ³ãƒˆãƒªï¼‰ã«æŠ‘ãˆã‚‹
                if conversationHistory.count > 12 {
                    conversationHistory.removeFirst(conversationHistory.count - 12)
                }
                turnCount += 2
                let updatedTurnCount = turnCount
                Task.detached { [weak self, userId, childId, sessionId, userTurn, aiTurn, updatedTurnCount, speakerChildId, speakerChildName] in
                    let repo = FirebaseConversationsRepository()
                    do {
                        try await repo.addTurn(userId: userId, childId: childId, sessionId: sessionId, turn: userTurn)
                        try await repo.addTurn(userId: userId, childId: childId, sessionId: sessionId, turn: aiTurn)
                        try? await repo.updateTurnCount(userId: userId, childId: childId, sessionId: sessionId, turnCount: updatedTurnCount)
                        if speakerChildId != nil || speakerChildName != nil {
                            try? await repo.updateSpeakerAttribution(
                                userId: userId,
                                childId: childId,
                                sessionId: sessionId,
                                speakerChildId: speakerChildId,
                                speakerChildName: speakerChildName
                            )
                        }
                    } catch {
                        await MainActor.run {
                            self?.logFirebaseError(error, operation: "ãƒ†ã‚­ã‚¹ãƒˆä¼šè©±ã®ä¿å­˜")
                        }
                    }
                }

                // å„ã‚¿ãƒ¼ãƒ³ã®çµ‚äº†æ™‚ã«ãƒ©ã‚¤ãƒ–è¦ç´„/ã‚¿ã‚°/æ–°èªã‚’ç”Ÿæˆã—ã¦å³æ™‚ä¿å­˜
                liveSummaryTask?.cancel()
                liveSummaryTask = Task { [weak self] in
                    print("ğŸ“ ConversationController: live analysis task start (turnCount=\(self?.inMemoryTurns.count ?? 0))")
                    await self?.generateLiveAnalysisAndPersist()
                    print("ğŸ“ ConversationController: live analysis task end (summary='\(self?.liveSummary ?? "")', interests=\(self?.liveInterests.map { $0.rawValue } ?? []), newWords=\(self?.liveNewVocabulary ?? []))")
                }
            }
        } catch {
            print("âŒ ConversationController: sendTextPreviewRequest failed - \(error)")
            await MainActor.run {
                guard self.isCurrentTurn(turnId) else { return }
                self.errorMessage = error.localizedDescription
                if self.isHandsFreeMode && self.isRecording {
                    self.resumeListening()
                } else {
                    self.turnState = .waitingUser
                }
            }
        }

        await MainActor.run {
            if self.isCurrentTurn(turnId) {
                self.isThinking = false
            }
        }
    }

    func sendAudioPreviewRequest() async {
        guard let client = audioPreviewClient else {
            await MainActor.run { self.errorMessage = "éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“" }
            return
        }

        // âœ… ã“ã®ã‚¿ãƒ¼ãƒ³ã®ã€Œè©±è€…ï¼ˆå­ï¼‰ã€ãƒ¡ã‚¿æƒ…å ±ã¯ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–‹å§‹æ™‚ç‚¹ã§ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã™ã‚‹
        // - Note: éŒ²éŸ³ä¸­ã«æŠ¼ã•ã‚Œã¦ã„ãŸåå‰ã‚’å„ªå…ˆã—ãŸã„ã®ã§ã€locked -> override ã®é †ã§è§£æ±ºã™ã‚‹
        let speakerChildIdForThisTurn = self.lockedSpeakerChildIdForTurn ?? self.speakerChildIdOverride
        let speakerChildNameForThisTurn = self.lockedSpeakerChildNameForTurn ?? self.speakerChildNameOverride
        // æ¬¡ã‚¿ãƒ¼ãƒ³ã¸æŒã¡è¶Šã•ãªã„
        self.lockedSpeakerChildIdForTurn = nil
        self.lockedSpeakerChildNameForTurn = nil

        await MainActor.run {
            // æ–°ã—ã„è¿”ç­”ã‚’é–‹å§‹ã™ã‚‹ã®ã§å‰ã®è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
            self.aiResponseText = ""
            self.turnMetrics.requestStart = Date()
            self.logTurnStageTiming(event: "request", at: self.turnMetrics.requestStart!)
        }

        let captured = recordedPCMData
        recordedPCMData.removeAll()
        guard !captured.isEmpty else {
            await MainActor.run {
                self.errorMessage = "éŸ³å£°ãŒéŒ²éŸ³ã•ã‚Œã¦ã„ã¾ã›ã‚“"
                if self.isHandsFreeMode && self.isRecording {
                    self.resumeListening()
                } else {
                    self.turnState = .waitingUser
                }
            }
            return
        }

        let turnId = advanceTurnId()
        ignoreIncomingAIChunks = false

        // AIãŒè€ƒãˆå§‹ã‚ã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ç›¸æ§Œã‚’æ‰“ã¤
        await MainActor.run {
            self.isThinking = true
            self.playRandomFiller()
        }

        let wav = pcm16ToWav(pcmData: captured, sampleRate: recordedSampleRate)

        // ãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°ã‚‚ä¼šè©±å±¥æ­´ã«ãƒ†ã‚­ã‚¹ãƒˆã§æ®‹ã™ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«ã§ä¸¦è¡Œã—ã¦æ–‡å­—èµ·ã“ã—ã‚’è©¦ã¿ã‚‹
        let userTranscriptionTask: Task<String?, Never>? = enableLocalUserTranscription
            ? Task.detached { [wavData = wav] in
                await ConversationController.transcribeUserAudio(wavData: wavData)
            }
            : nil

        let tStart = Date()
        print("ğŸ§© ConversationController: systemPrompt audioMissingBoost=\(audioMissingConsecutiveCount > 0) (consecutive=\(audioMissingConsecutiveCount))")
        let promptHead = String(currentSystemPrompt.prefix(140)).replacingOccurrences(of: "\n", with: "\\n")
        print("ğŸ§© ConversationController: systemPrompt head(140)=\(promptHead)")
        print("â±ï¸ ConversationController: sendAudioPreviewRequest start - pcmBytes=\(captured.count), sampleRate=\(recordedSampleRate)")
        await MainActor.run {
            self.player.prepareForNextStream()
        }

        do {
            let result = try await client.streamResponse(
                audioData: wav,
                systemPrompt: currentSystemPrompt,
                history: conversationHistory,
                userMessagePrefix: audioPreviewUserMessagePrefix,
                onText: { [weak self] delta in
                    guard let self else { return }
                    Task { @MainActor in
                        guard !self.ignoreIncomingAIChunks, self.isCurrentTurn(turnId) else { return }
                        if self.turnMetrics.firstText == nil {
                            self.turnMetrics.firstText = Date()
                            self.logTurnStageTiming(event: "firstText", at: self.turnMetrics.firstText!)
                        }
                        let clean = self.sanitizeAIText(delta)
                        if clean.isEmpty { return }
                        print("ğŸŸ¦ onText delta (clean):", clean)
                        self.aiResponseText += clean
                    }
                },
                onAudioChunk: { [weak self] chunk in
                    guard let self else { return }
                    Task { @MainActor in
                        guard !self.ignoreIncomingAIChunks, self.isCurrentTurn(turnId) else { return }
                        print("ğŸ”Š onAudioChunk bytes:", chunk.count)
                        self.playbackTurnId = turnId
                        self.turnState = .speaking
                        // ç›¸æ§ŒãŒé³´ã£ã¦ã„ã¦ã‚‚å¼·åˆ¶åœæ­¢ã›ãšè‡ªç„¶ã«çµ‚ã‚ã‚‰ã›ã‚‹
                        if self.isFillerPlaying {
                            self.isFillerPlaying = false
                        }
                        self.handleFirstAudioChunk(for: turnId)
                        self.player.resumeIfNeeded()
                        // å‡ºåŠ›ã¯pcm16æŒ‡å®šãªã®ã§ãã®ã¾ã¾å†ç”Ÿ
                        self.player.playChunk(chunk)
                    }
                },
                onFirstByte: { [weak self] firstByte in
                    guard let self else { return }
                    Task { @MainActor in
                        guard !self.ignoreIncomingAIChunks, self.isCurrentTurn(turnId) else { return }
                        self.turnMetrics.firstByte = firstByte
                        self.logTurnStageTiming(event: "firstByte", at: firstByte)
                    }
                }
            )
            let tEnd = Date()
            print("â±ï¸ ConversationController: streamResponse completed in \(String(format: "%.2f", tEnd.timeIntervalSince(tStart)))s, finalText.count=\(result.text.count), finalText=\"\(result.text)\", audioMissing=\(result.audioMissing)")
            audioMissingConsecutiveCount = result.audioMissing ? min(audioMissingConsecutiveCount + 1, 3) : 0
            let cleanFinal = self.sanitizeAIText(result.text)
            guard self.isCurrentTurn(turnId) else { return }
            turnMetrics.streamComplete = tEnd
            logTurnStageTiming(event: "streamComplete", at: tEnd)
            logTurnLatencySummary(context: "stream complete")

            await MainActor.run {
                // å¹ãå‡ºã—ç”¨ã«æœ€çµ‚ãƒ†ã‚­ã‚¹ãƒˆã‚’UIã¸åæ˜ ï¼ˆéŸ³å£°ã®ã¿ã®å ´åˆã§ã‚‚ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥ã‚Œã‚‹ï¼‰
                self.aiResponseText = cleanFinal
                print("ğŸŸ© set aiResponseText final:", cleanFinal)
                if !result.audioMissing {
                    if self.isHandsFreeMode && self.isRecording && self.turnState != .speaking {
                        self.resumeListening()
                    } else if self.turnState != .speaking {
                        self.turnState = .waitingUser
                        self.startWaitingForResponse()
                    }
                } else {
                    print("ğŸº ConversationController: audio missing from stream -> fallback TTS will run")
                }
            }

            if result.audioMissing {
                await self.playFallbackTTS(text: cleanFinal, turnId: turnId)
            }

            // Firebaseä¿å­˜ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°ã‚‚ãƒ­ãƒ¼ã‚«ãƒ«æ–‡å­—èµ·ã“ã—ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ï¼‰
            if let userId = currentUserId, let childId = currentChildId, let sessionId = currentSessionId {
                let speakerChildId = speakerChildIdForThisTurn
                let speakerChildName = speakerChildNameForThisTurn
                let userText = await userTranscriptionTask?.value?.trimmingCharacters(in: CharacterSet.whitespacesAndNewlines)
                let userTurn = FirebaseTurn(role: .child, text: userText?.isEmpty == false ? userText! : "(voice)", timestamp: Date())
                let aiTurn = FirebaseTurn(role: .ai, text: cleanFinal, timestamp: Date())
                print("ğŸ—‚ï¸ ConversationController: append inMemoryTurns (user:'\(userTurn.text ?? "nil")', ai:'\(aiTurn.text ?? "nil")')")
                inMemoryTurns.append(contentsOf: [userTurn, aiTurn])
                // âœ… å±¥æ­´ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ç©ã‚€ï¼ˆç›´è¿‘ã®æ–‡è„ˆã¨ã—ã¦ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹APIã¸æ¸¡ã™ï¼‰
                let historyUserText = userText?.isEmpty == false ? userText! : "(ä¸æ˜ç­ãªéŸ³å£°)"
                self.lastCommittedUserText = historyUserText
                conversationHistory.append(HistoryItem(role: "user", text: historyUserText))
                conversationHistory.append(HistoryItem(role: "assistant", text: cleanFinal))
                // å±¥æ­´ãŒé•·ããªã‚Šã™ããªã„ã‚ˆã†ã«6ã‚¿ãƒ¼ãƒ³åˆ†ï¼ˆ12ã‚¨ãƒ³ãƒˆãƒªï¼‰ã«æŠ‘ãˆã‚‹
                if conversationHistory.count > 12 {
                    conversationHistory.removeFirst(conversationHistory.count - 12)
                }
                turnCount += 2
                let updatedTurnCount = turnCount
                Task.detached { [weak self, userId, childId, sessionId, userTurn, aiTurn, updatedTurnCount, speakerChildId, speakerChildName] in
                    let repo = FirebaseConversationsRepository()
                    do {
                        try await repo.addTurn(userId: userId, childId: childId, sessionId: sessionId, turn: userTurn)
                        try await repo.addTurn(userId: userId, childId: childId, sessionId: sessionId, turn: aiTurn)
                        try? await repo.updateTurnCount(userId: userId, childId: childId, sessionId: sessionId, turnCount: updatedTurnCount)
                        if speakerChildId != nil || speakerChildName != nil {
                            try? await repo.updateSpeakerAttribution(
                                userId: userId,
                                childId: childId,
                                sessionId: sessionId,
                                speakerChildId: speakerChildId,
                                speakerChildName: speakerChildName
                            )
                        }
                    } catch {
                        await MainActor.run {
                            self?.logFirebaseError(error, operation: "éŸ³å£°ä¼šè©±ã®ä¿å­˜")
                        }
                    }
                }

                // å„ã‚¿ãƒ¼ãƒ³ã®çµ‚äº†æ™‚ã«ãƒ©ã‚¤ãƒ–è¦ç´„/ã‚¿ã‚°/æ–°èªã‚’ç”Ÿæˆã—ã¦å³æ™‚ä¿å­˜
                liveSummaryTask?.cancel()
                liveSummaryTask = Task { [weak self] in
                    print("ğŸ“ ConversationController: live analysis task start (turnCount=\(self?.inMemoryTurns.count ?? 0))")
                    await self?.generateLiveAnalysisAndPersist()
                    print("ğŸ“ ConversationController: live analysis task end (summary='\(self?.liveSummary ?? "")', interests=\(self?.liveInterests.map { $0.rawValue } ?? []), newWords=\(self?.liveNewVocabulary ?? []))")
                }
            }
        } catch {
            print("âŒ ConversationController: streamResponse failed - \(error)")
            await MainActor.run {
                guard self.isCurrentTurn(turnId) else { return }
                self.errorMessage = error.localizedDescription
                if self.isHandsFreeMode && self.isRecording {
                    self.resumeListening()
                } else {
                    self.turnState = .waitingUser
                }
            }
        }

        await MainActor.run {
            if self.isCurrentTurn(turnId) {
                self.isThinking = false
            }
        }
    }

    func persistVoiceOnlyTurn() async {
        let placeholder = "(voice)"
        print("ğŸŸ¨ persistVoiceOnlyTurn: saving placeholder '\(placeholder)'")
        lastCommittedUserText = placeholder
        inMemoryTurns.append(FirebaseTurn(role: .child, text: placeholder, timestamp: Date()))
        conversationHistory.append(HistoryItem(role: "user", text: placeholder))
        if conversationHistory.count > 12 {
            conversationHistory.removeFirst(conversationHistory.count - 12)
        }
        turnCount += 1
        let updatedTurnCount = turnCount

        guard let userId = currentUserId, let childId = currentChildId, let sessionId = currentSessionId else { return }
        // ã§ãã‚‹ã ã‘éŒ²éŸ³ä¸­ã®æŠ¼ä¸‹ã‚’å„ªå…ˆã—ã¦ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
        let speakerChildId = self.lockedSpeakerChildIdForTurn ?? self.speakerChildIdOverride
        let speakerChildName = self.lockedSpeakerChildNameForTurn ?? self.speakerChildNameOverride
        Task.detached { [weak self, userId, childId, sessionId, updatedTurnCount, speakerChildId, speakerChildName] in
            let repo = FirebaseConversationsRepository()
            do {
                let userTurn = FirebaseTurn(role: .child, text: placeholder, timestamp: Date())
                try await repo.addTurn(userId: userId, childId: childId, sessionId: sessionId, turn: userTurn)
                try? await repo.updateTurnCount(userId: userId, childId: childId, sessionId: sessionId, turnCount: updatedTurnCount)
                if speakerChildId != nil || speakerChildName != nil {
                    try? await repo.updateSpeakerAttribution(
                        userId: userId,
                        childId: childId,
                        sessionId: sessionId,
                        speakerChildId: speakerChildId,
                        speakerChildName: speakerChildName
                    )
                }
            } catch {
                await MainActor.run {
                    self?.logFirebaseError(error, operation: "éŸ³å£°ã®ã¿ã‚¿ãƒ¼ãƒ³ã®ä¿å­˜")
                }
            }
        }
    }
}
