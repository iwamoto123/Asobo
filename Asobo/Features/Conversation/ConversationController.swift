//
//  ConversationController.swift
//

import Foundation
import AVFoundation
import Speech
import Domain
import Services
import Support

@MainActor
public final class ConversationController: ObservableObject {

    // MARK: - UI State
    public enum Mode: String, CaseIterable { case localSTT, realtime }

    @Published public var mode: Mode = .localSTT
    @Published public var transcript: String = ""
    @Published public var isRecording: Bool = false
    @Published public var errorMessage: String?
    @Published public var isRealtimeActive: Bool = false
    @Published public var isRealtimeConnecting: Bool = false
    
    // è¿½åŠ : ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒåœæ­¢ã—ãŸã‹ã‚’è¦šãˆã‚‹ãƒ•ãƒ©ã‚°
    private var userStoppedRecording = false
    
    // âœ… AIéŸ³å£°å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°ï¼ˆonAudioDeltaReceivedã§è¨­å®šã€sendMicrophonePCMã®æ—©æœŸreturnã‚’ä¸€å…ƒåŒ–ï¼‰
    private var isAIPlayingAudio: Bool = false
    
    // âœ… ã‚¿ãƒ¼ãƒ³çŠ¶æ…‹ï¼ˆæ‹¡å¼µç‰ˆï¼‰
    enum TurnState {
        case idle               // ã‚»ãƒƒã‚·ãƒ§ãƒ³å‰ or çµ‚äº†å¾Œ
        case waitingUser        // åˆå›/æ¯ã‚¿ãƒ¼ãƒ³ï¼šã¾ãšãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å£°ã‚’å¾…ã¤
        case nudgedByAI(Int)   // ä¿ƒã—(ä½•å›ç›®ã‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)
        case listening          // VADãŒ speech_started ã€œ speech_stopped ã®é–“
        case thinking           // commit æ¸ˆã¿ã€œå¿œç­”ç”Ÿæˆä¸­
        case speaking           // AIãŒTTSå‡ºåŠ›ä¸­
        case clarifying         // èãå–ã‚Šä¸å¯â†’èãè¿”ã—ä¸­
    }
    @Published private var turnState: TurnState = .idle
    
    // âœ… ã€Œå¾…ã¤â†’ä¿ƒã™ã€ã‚¿ã‚¤ãƒãƒ¼
    private var nudgeTimer: Timer?
    
    // ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    @Published public var aiResponseText: String = ""
    @Published public var isPlayingAudio: Bool = false
    @Published public var hasMicrophonePermission: Bool = false
    
    // AIå‘¼ã³å‡ºã—ç”¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    @Published public var isThinking: Bool = false   // ãã‚‹ãã‚‹è¡¨ç¤ºç”¨
    private var lastAskedText: String = ""           // åŒæ–‡ã®é€£æŠ•é˜²æ­¢

    // MARK: - Local STT (Speech) - DIå¯¾å¿œ
    private let audioEngine = AVAudioEngine()
    private let audioSession: AudioSessionManaging
    private let speech: SpeechRecognizing
    private var sttRequest: SFSpeechAudioBufferRecognitionRequest?
    private var sttTask: SpeechRecognitionTasking?

    // MARK: - Realtime (OpenAI)
    private let audioSessionManager = AudioSessionManager()
    private var mic: MicrophoneCapture?
    private var player = PlayerNodeStreamer()            // éŸ³å£°å…ˆå‡ºã—ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    private var realtimeClient: RealtimeClientOpenAI?
    private var receiveTextTask: Task<Void, Never>?
    private var receiveAudioTask: Task<Void, Never>?
    private var receiveInputTextTask: Task<Void, Never>?
    private var sessionStartTask: Task<Void, Never>?     // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚¿ã‚¹ã‚¯ã®ç®¡ç†

    // MARK: - Lifecycle
    public init(
        audioSession: AudioSessionManaging = SystemAudioSessionManager(),
        speech: SpeechRecognizing = SystemSpeechRecognizer(locale: "ja-JP")
    ) {
        self.audioSession = audioSession
        self.speech = speech
    }

    deinit {
        Task { @MainActor in
            self.stopLocalTranscription()
            self.stopRealtimeSession()
        }
    }

    // MARK: - Permissions
    public func requestPermissions() {
        AVAudioSession.sharedInstance().requestRecordPermission { [weak self] granted in
            DispatchQueue.main.async {
                self?.hasMicrophonePermission = granted
            }
        }
        SFSpeechRecognizer.requestAuthorization { _ in }
    }

    // MARK: - Local STT (DIå¯¾å¿œç‰ˆ)
    public func startLocalTranscription() {
        guard !isRecording else { return }
        guard speech.isAvailable else {
            self.errorMessage = "éŸ³å£°èªè­˜ãŒç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
            return
        }

        // 1) AudioSession ã‚’å…ˆã«æ§‹æˆï¼ˆDIçµŒç”±ï¼‰
        do { try audioSession.configure() }
        catch {
            self.errorMessage = "AudioSessioné–‹å§‹ã«å¤±æ•—: \(error.localizedDescription)"
            return
        }

        // 2) ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
        let req = SFSpeechAudioBufferRecognitionRequest()
        req.shouldReportPartialResults = true
        self.sttRequest = req
        self.transcript = ""
        self.errorMessage = nil

        // 3) ãƒã‚¤ã‚¯ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¸æµã™ï¼ˆformat: nil ã§è£…ç½®ã®æ­£ã—ã„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«è¿½éšï¼‰
        let input = audioEngine.inputNode
        input.removeTap(onBus: 0)
        input.installTap(onBus: 0, bufferSize: 1024, format: nil) { [weak self] buffer, _ in
            self?.sttRequest?.append(buffer)
        }

        // 4) ã‚¨ãƒ³ã‚¸ãƒ³èµ·å‹•
        do {
            audioEngine.prepare()
            try audioEngine.start()
        } catch {
            self.errorMessage = "AudioEngineé–‹å§‹ã«å¤±æ•—: \(error.localizedDescription)"
            input.removeTap(onBus: 0)
            self.sttRequest = nil
            return
        }

        // 5) èªè­˜ï¼ˆãƒ—ãƒ­ãƒˆã‚³ãƒ«çµŒç”±ï¼‰
        sttTask = speech.startTask(
            request: req,
            onResult: { [weak self] text, isFinal in
                Task { @MainActor in
                    self?.transcript = text
                    if isFinal { self?.stopLocalTranscription() }
                }
            },
            onError: { [weak self] err in
                guard let self else { return }
                
                // ã‚­ãƒ£ãƒ³ã‚»ãƒ«/ç„¡éŸ³ãªã©ã®"æ­£å¸¸çµ‚äº†æ‰±ã„"ã¯ UI ã«å‡ºã•ãªã„
                if self.userStoppedRecording || Self.isBenignSpeechError(err) {
                    Task { @MainActor in self.finishSTTCleanup() }
                    return
                }
                
                // ãã‚Œä»¥å¤–ã®ã¿ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
                Task { @MainActor in
                    self.errorMessage = err.localizedDescription
                    self.finishSTTCleanup()
                }
            }
        )

        isRecording = true
        mode = .localSTT
    }

    public func stopLocalTranscription() {
        guard isRecording || sttTask != nil else { return }
        userStoppedRecording = true                // ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã¦ã‹ã‚‰
        audioEngine.inputNode.removeTap(onBus: 0)
        audioEngine.stop()
        sttRequest?.endAudio()
        sttTask?.cancel()                          // ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã¯å¿…è¦ã€‚ä¸Šã§ç„¡å®³æ‰±ã„ã«ã™ã‚‹
        finishSTTCleanup()
    }

    // MARK: - Realtimeï¼ˆæ¬¡ã®æ®µéšï¼šä¼šè©±ï¼‰
    public func startRealtimeSession() {
        // æ—¢ã«æ¥ç¶šä¸­ã¾ãŸã¯æ¥ç¶šæ¸ˆã¿ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
        guard !isRealtimeActive && !isRealtimeConnecting else {
            print("âš ï¸ ConversationController: æ—¢ã«Realtimeã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã¾ãŸã¯æ¥ç¶šä¸­ã§ã™")
            return
        }
        
        // æ—¢å­˜ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        sessionStartTask?.cancel()
        
        // æ—¢å­˜ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒã‚ã‚Œã°å®Œå…¨ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if realtimeClient != nil {
            print("ğŸ§¹ ConversationController: æ—¢å­˜ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
            Task {
                try? await realtimeClient?.finishSession()
                await MainActor.run {
                    self.realtimeClient = nil
                    self.startRealtimeSessionInternal()
                }
            }
            return
        }
        
        startRealtimeSessionInternal()
    }
    
    private func startRealtimeSessionInternal() {
        // æ¥ç¶šä¸­ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
        isRealtimeConnecting = true
        
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ§‹æˆ
        do {
            try audioSessionManager.configure()
            
            // AudioSessionè¨­å®šå¾Œã«PlayerNodeStreamerã®ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é–‹å§‹
            // âš ï¸ é‡è¦ãªé †åºï¼šAudioSessionã‚’è¨­å®šã—ã¦ã‹ã‚‰ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é–‹å§‹
            try player.start()
            
            // éŸ³é‡ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            let audioSession = AVAudioSession.sharedInstance()
            print("ğŸ“Š ConversationController: ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªè¨­å®šç¢ºèª")
            print("   - OutputVolume: \(audioSession.outputVolume) (1.0ãŒæœ€å¤§)")
            print("   - OutputChannels: \(audioSession.outputNumberOfChannels)")
            print("   - SampleRate: \(audioSession.sampleRate)Hz")
            
            if audioSession.outputVolume < 0.1 {
                print("âš ï¸ ConversationController: éŸ³é‡ãŒéå¸¸ã«ä½ã„ã§ã™ï¼ˆ\(audioSession.outputVolume)ï¼‰ã€‚ãƒ‡ãƒã‚¤ã‚¹ã®éŸ³é‡è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            }
            
            print("âœ… ConversationController: AudioSessionè¨­å®šã¨PlayerNodeStreameré–‹å§‹æˆåŠŸ")
        } catch {
            self.errorMessage = "AudioSessionæ§‹æˆã«å¤±æ•—: \(error.localizedDescription)"
            print("âŒ ConversationController: AudioSessionæ§‹æˆå¤±æ•— - \(error.localizedDescription)")
            
            // è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
            if let nsError = error as NSError? {
                print("   - Error Domain: \(nsError.domain)")
                print("   - Error Code: \(nsError.code)")
                print("   - Error Info: \(nsError.userInfo)")
            }
        }

        // ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLï¼ˆREALTIME_WSS_URL ãŒã‚ã‚Œã°å„ªå…ˆï¼‰
        let url: URL = {
            if let s = Bundle.main.object(forInfoDictionaryKey: "REALTIME_WSS_URL") as? String,
               let u = URL(string: s) { 
                print("ğŸ”— ConversationController: ç›´æ¥URLä½¿ç”¨ - \(s)")
                return u 
            }

            if let https = URL(string: AppConfig.realtimeEndpoint),
               var comps = URLComponents(url: https, resolvingAgainstBaseURL: false) {
                let isHTTP = comps.scheme?.lowercased() == "http"
                comps.scheme = isHTTP ? "ws" : "wss"   // èª­ã¿ã¨æ›¸ãã‚’åˆ†é›¢
                let finalUrl = comps.url ?? https
                print("ğŸ”— ConversationController: æ§‹ç¯‰URLä½¿ç”¨ - \(finalUrl)")
                return finalUrl
            }

            // âœ… gpt-realtime ã«å›ºå®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å®Œå…¨æ’é™¤ï¼‰
            let fallbackUrl = URL(string: "wss://api.openai.com/v1/realtime?model=gpt-realtime")!
            print("ğŸ”— ConversationController: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯URLä½¿ç”¨ - \(fallbackUrl)")
            return fallbackUrl
        }()

        let key = AppConfig.openAIKey
        print("ğŸ”‘ ConversationController: APIã‚­ãƒ¼ç¢ºèª - \(key.prefix(10))...")
        guard !key.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty else {
            self.errorMessage = "OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ï¼ˆSecrets.xcconfig ã‚’ç¢ºèªï¼‰"
            return
        }
        
        // APIã‚­ãƒ¼ã®å½¢å¼ã‚’ãƒã‚§ãƒƒã‚¯
        guard key.hasPrefix("sk-") else {
            self.errorMessage = "APIã‚­ãƒ¼ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ï¼ˆsk-ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰"
            return
        }

        realtimeClient = RealtimeClientOpenAI(url: url, apiKey: key)
        
        // Realtimeã®ã‚¤ãƒ™ãƒ³ãƒˆã«ãƒ•ãƒƒã‚¯
        realtimeClient?.onSpeechStarted = { [weak self] in
            Task { @MainActor in
                guard let self else { return }
                // ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã‚’æ¤œçŸ¥ â†’ ä¿ƒã—ã‚¿ã‚¤ãƒãƒ¼ã¯æ­¢ã‚ã‚‹ & AIéŸ³å£°ã‚’å³åœæ­¢
                self.cancelNudge()
                self.turnState = .listening
                // âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—å§‹ã‚ãŸã‚‰å³AIéŸ³å£°ã‚’æ­¢ã‚ã‚‹
                self.player.stopImmediately()
            }
        }
        
        realtimeClient?.onSpeechStopped = { [weak self] in
            Task { @MainActor in
                guard let self else { return }
                self.turnState = .thinking
                // ä»¥é™ã¯ Realtime å´ãŒ commit â†’ response.create ã‚’é€ä¿¡ã—ã¦ãã‚Œã‚‹è¨­è¨ˆã«ã—ã¦ã„ã‚‹
            }
        }
        
        realtimeClient?.onInputCommitted = { [weak self] transcript in
            Task { @MainActor in
                guard let self else { return }
                let t = transcript.trimmingCharacters(in: .whitespacesAndNewlines)
                if t.count < 2 {
                    // âœ… èãå–ã‚Šå¤±æ•—æ™‚ã¯å¿…ãšèãè¿”ã—ï¼ˆRealtimeClientå´ã§å‡¦ç†æ¸ˆã¿ï¼‰
                    self.turnState = .clarifying
                } else {
                    // âœ… èãå–ã‚ŠæˆåŠŸ â†’ å¿œç­”ç”Ÿæˆä¸­
                    self.turnState = .thinking
                }
            }
        }
        
        realtimeClient?.onResponseCreated = { [weak self] in
            Task { @MainActor in
                guard let self else { return }
                // âœ… æ–°ã—ã„å¿œç­”ãŒä½œæˆã•ã‚ŒãŸæ™‚ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ï¼ˆå‰ã®å¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¶ˆã™ï¼‰
                self.aiResponseText = ""
                print("ğŸ“ ConversationController: æ–°ã—ã„å¿œç­”é–‹å§‹ - aiResponseTextã‚’ã‚¯ãƒªã‚¢")
                // âœ… éŸ³å£°å†ç”Ÿã‚’å†é–‹ï¼ˆstopImmediately()ã§volume=0ã«ãªã£ãŸå ´åˆã®å¾©å¸°ï¼‰
                self.player.resumeIfNeeded()
            }
        }
        
        realtimeClient?.onResponseDone = { [weak self] in
            Task { @MainActor in
                guard let self else { return }
                // âœ… å¿œç­”ãŒçµ‚ã‚ã£ãŸã‚‰æ¬¡ã‚¿ãƒ¼ãƒ³ã¸ï¼šã¾ãšã¯ã€Œå¾…ã¤ã€
                // âœ… AIéŸ³å£°å†ç”Ÿãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆæ¬¡ã®ã‚¿ãƒ¼ãƒ³ã§éŒ²éŸ³ã‚’å†é–‹ã§ãã‚‹ã‚ˆã†ã«ï¼‰
                self.isAIPlayingAudio = false
                self.startWaiting()
            }
        }
        
        // âœ… å‚è€ƒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ï¼šAIéŸ³å£°å—ä¿¡æ™‚ã«éŒ²éŸ³åœæ­¢ã‚’ãƒˆãƒªã‚¬ãƒ¼
        realtimeClient?.onAudioDeltaReceived = { [weak self] in
            Task { @MainActor in
                guard let self else { return }
                // âœ… AIéŸ³å£°å—ä¿¡æ™‚ã«ãƒ•ãƒ©ã‚°ã‚’è¨­å®šï¼ˆsendMicrophonePCMã®æ—©æœŸreturnã‚’ä¸€å…ƒåŒ–ï¼‰
                self.isAIPlayingAudio = true
                print("ğŸ›‘ ConversationController: AIéŸ³å£°å—ä¿¡ - éŒ²éŸ³åœæ­¢ãƒ•ãƒ©ã‚°è¨­å®šï¼ˆisAIPlayingAudio=trueï¼‰")
            }
        }
        
        // çŠ¶æ…‹å¤‰æ›´ã‚’ç›£è¦–
        realtimeClient?.onStateChange = { [weak self] state in
            Task { @MainActor in
                switch state {
                case .connecting:
                    self?.isRealtimeConnecting = true
                    self?.isRealtimeActive = false
                case .ready:
                    self?.isRealtimeConnecting = false
                    self?.isRealtimeActive = true
                case .closed(let error):
                    self?.isRealtimeConnecting = false
                    self?.isRealtimeActive = false
                    if let error = error {
                        self?.errorMessage = "æ¥ç¶šã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
                    }
                case .idle:
                    self?.isRealtimeConnecting = false
                    self?.isRealtimeActive = false
                default:
                    self?.isRealtimeConnecting = false
                    self?.isRealtimeActive = false
                }
            }
        }
        
        transcript = ""
        aiResponseText = ""
        errorMessage = nil
        turnState = .waitingUser  // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã™ã®ã‚’å¾…ã¤

        sessionStartTask = Task {
            do {
                print("ğŸš€ ConversationController: Realtimeã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹")
                
                // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒ†ã‚¹ãƒˆ
                print("ğŸŒ ConversationController: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒ†ã‚¹ãƒˆä¸­...")
                let testUrl = URL(string: "https://api.openai.com/v1/models")!
                var testRequest = URLRequest(url: testUrl)
                testRequest.addValue("Bearer \(key)", forHTTPHeaderField: "Authorization")
                testRequest.timeoutInterval = 10
                
                let (_, response) = try await URLSession.shared.data(for: testRequest)
                if let httpResponse = response as? HTTPURLResponse {
                    print("ğŸŒ ConversationController: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆçµæœ - Status: \(httpResponse.statusCode)")
                    if httpResponse.statusCode == 401 {
                        await MainActor.run {
                            self.errorMessage = "APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ï¼ˆ401 Unauthorizedï¼‰"
                            self.isRealtimeConnecting = false
                        }
                        return
                    }
                }
                
                try await realtimeClient?.startSession(child: ChildProfile.sample(), context: [])
                print("âœ… ConversationController: ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æˆåŠŸ")
                
                // çŠ¶æ…‹ã‚’æ›´æ–°
                await MainActor.run {
                    self.isRealtimeConnecting = false
                    self.isRealtimeActive = true
                    self.mode = .realtime
                    self.startReceiveLoops()
                    
                    // âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã«ãƒã‚¤ã‚¯ã‚’é–‹å§‹ã—ã¦ã€å¸¸ã«éŸ³å£°å…¥åŠ›ã‚’ç›£è¦–ã™ã‚‹
                    guard let client = self.realtimeClient else {
                        print("âš ï¸ ConversationController: ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹å¾Œã€realtimeClientãŒnil")
                        return
                    }
                    self.mic?.stop()
                    self.mic = MicrophoneCapture { [weak self] buf in
                        guard let self = self else { return }
                        // âœ… AIéŸ³å£°å†ç”Ÿä¸­ã¯éŸ³å£°é€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆonAudioDeltaReceivedã§è¨­å®šã•ã‚ŒãŸãƒ•ãƒ©ã‚°ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
                        if self.isAIPlayingAudio {
                            // AIãŒè©±ã—ã¦ã„ã‚‹é–“ã¯éŸ³å£°é€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—
                            return
                        }
                        Task { try? await client.sendMicrophonePCM(buf) }
                    }
                    do {
                        try self.mic?.start()
                        print("âœ… ConversationController: ãƒã‚¤ã‚¯é–‹å§‹æˆåŠŸï¼ˆå¸¸æ™‚ç›£è¦–ãƒ¢ãƒ¼ãƒ‰ï¼‰")
                    } catch {
                        print("âš ï¸ ConversationController: ãƒã‚¤ã‚¯é–‹å§‹å¤±æ•— - \(error.localizedDescription)")
                        self.errorMessage = "ãƒã‚¤ã‚¯é–‹å§‹ã«å¤±æ•—: \(error.localizedDescription)"
                    }
                    
                    // âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹å¾Œã€ã¾ãšã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å£°ã‚’å¾…ã¤
                    self.startWaiting()
                }
            } catch {
                print("âŒ ConversationController: ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹å¤±æ•— - \(error.localizedDescription)")
                await MainActor.run {
                    if let urlError = error as? URLError {
                        switch urlError.code {
                        case .notConnectedToInternet:
                            self.errorMessage = "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒã‚ã‚Šã¾ã›ã‚“"
                        case .timedOut:
                            self.errorMessage = "æ¥ç¶šãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
                        case .cannotConnectToHost:
                            self.errorMessage = "ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“"
                        default:
                            self.errorMessage = "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: \(urlError.localizedDescription)"
                        }
                    } else {
                        self.errorMessage = "Realtimeæ¥ç¶šå¤±æ•—: \(error.localizedDescription)"
                    }
                    self.isRealtimeConnecting = false
                    self.isRealtimeActive = false
                }
            }
        }
    }

    public func stopRealtimeSession() {
        print("ğŸ›‘ ConversationController: Realtimeã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†")
        
        // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        sessionStartTask?.cancel()
        sessionStartTask = nil
        
        // å—ä¿¡ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        receiveTextTask?.cancel(); receiveTextTask = nil
        receiveAudioTask?.cancel(); receiveAudioTask = nil
        receiveInputTextTask?.cancel(); receiveInputTextTask = nil
        
        // ãƒã‚¤ã‚¯ã¨ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’åœæ­¢
        mic?.stop(); mic = nil
        player.stop()
        
        // âœ… ä¿ƒã—ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢
        cancelNudge()
        
        // çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        isRecording = false
        isRealtimeActive = false
        isRealtimeConnecting = false
        turnState = .idle
        
        // ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
        transcript = ""
        aiResponseText = ""
        
        // ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¯ãƒªã‚¢
        errorMessage = nil
        
        Task {
            try? await realtimeClient?.finishSession()
            await MainActor.run {
                self.realtimeClient = nil
                print("âœ… ConversationController: ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            }
        }
    }

    public func startPTTRealtime() {
        guard let client = realtimeClient else {
            self.errorMessage = "Realtimeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"; return
        }
        cancelNudge()             // âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—å§‹ã‚ã‚‹ã®ã§ä¿ƒã—ã‚’æ­¢ã‚ã‚‹
        // ğŸ”‡ ã„ã¾æµã‚Œã¦ã„ã‚‹AIéŸ³å£°ã‚’æ­¢ã‚ã‚‹ï¼ˆbarge-in å‰æï¼‰
        player.stop()
        Task { try? await client.interruptAndYield() }   // â† ã‚µãƒ¼ãƒå´ã®ç™ºè©±ã‚‚ä¸­æ–­

        // âœ… å…¬å¼ãƒ‘ã‚¿ãƒ¼ãƒ³: PTTé–‹å§‹æ™‚ã« input_audio_buffer.clear ã‚’é€ä¿¡ï¼ˆinterruptAndYieldå†…ã§é€ä¿¡ã•ã‚Œã‚‹ãŸã‚è¿½åŠ ä¸è¦ï¼‰
        // âœ… interruptAndYield() ãŒæ—¢ã« input_audio_buffer.clear ã‚’é€ä¿¡ã—ã¦ã„ã‚‹ãŸã‚ã€ã“ã“ã§ã¯è¿½åŠ ä¸è¦

        mic?.stop()
        mic = MicrophoneCapture { [weak self] buf in
            guard let self = self else { return }
            // âœ… AIéŸ³å£°å†ç”Ÿä¸­ã¯éŸ³å£°é€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆonAudioDeltaReceivedã§è¨­å®šã•ã‚ŒãŸãƒ•ãƒ©ã‚°ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
            if self.isAIPlayingAudio {
                // AIãŒè©±ã—ã¦ã„ã‚‹é–“ã¯éŸ³å£°é€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—
                return
            }
            Task { try? await client.sendMicrophonePCM(buf) }
        }
        do {
            try mic?.start()
            isRecording = true
            transcript = ""
            turnState = .listening
        } catch {
            self.errorMessage = "ãƒã‚¤ã‚¯é–‹å§‹ã«å¤±æ•—: \(error.localizedDescription)"
            isRecording = false
        }
    }

    public func stopPTTRealtime() {
        isRecording = false
        mic?.stop()
        // âœ… å…¬å¼ãƒ‘ã‚¿ãƒ¼ãƒ³: PTTçµ‚äº†æ™‚ã« commit â†’ response.create ã‚’é€ä¿¡
        Task { [weak self] in
            guard let self = self, let client = self.realtimeClient else { return }
            do {
                try await client.commitInputAndRequestResponse()
                print("âœ… ConversationController: PTTçµ‚äº† - commit â†’ response.createé€ä¿¡å®Œäº†")
            } catch {
                print("âš ï¸ ConversationController: PTTçµ‚äº†å‡¦ç†å¤±æ•— - \(error)")
            }
        }
    }

    private func startReceiveLoops() {
        print("ğŸ”„ ConversationController: startReceiveLoopsé–‹å§‹")
        
        // è¿”ç­”ãƒ†ã‚­ã‚¹ãƒˆï¼ˆpartialï¼‰ãƒ«ãƒ¼ãƒ—
        receiveTextTask?.cancel()
        receiveTextTask = Task { [weak self] in
            guard let self else { return }
            print("ğŸ”„ ConversationController: AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆãƒ«ãƒ¼ãƒ—é–‹å§‹")
            while !Task.isCancelled {
                do {
                    if let part = try await self.realtimeClient?.nextPartialText() {
                        print("ğŸ“ ConversationController: AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆå—ä¿¡ - \(part)")
                        await MainActor.run { 
                            // AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½è¨˜
                            if self.aiResponseText.isEmpty { 
                                self.aiResponseText = part 
                            } else { 
                                self.aiResponseText += part   // â† è¿½è¨˜
                            }
                            print("ğŸ“ ConversationController: aiResponseTextæ›´æ–° - \(self.aiResponseText)")
                        }
                    } else {
                        try await Task.sleep(nanoseconds: 50_000_000) // idle 50ms
                    }
                } catch { 
                    // CancellationErrorã¯æ­£å¸¸ãªçµ‚äº†ãªã®ã§ãƒ­ã‚°ã«å‡ºåŠ›ã—ãªã„
                    if !(error is CancellationError) {
                        print("âŒ ConversationController: AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼ - \(error)")
                    }
                    break 
                }
            }
        }

        // éŸ³å£°å…¥åŠ›ã®ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
        receiveInputTextTask?.cancel()
        receiveInputTextTask = Task { [weak self] in
            guard let self else { return }
            print("ğŸ”„ ConversationController: éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒ«ãƒ¼ãƒ—é–‹å§‹")
            var lastLogTime = Date()
            while !Task.isCancelled {
                do {
                    if let inputText = try await self.realtimeClient?.nextInputText() {
                        let trimmed = inputText.trimmingCharacters(in: .whitespacesAndNewlines)
                        print("ğŸ¤ ConversationController: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ãƒ†ã‚­ã‚¹ãƒˆå—ä¿¡ - ã€Œ\(trimmed)ã€")
                        await MainActor.run { 
                            // ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½è¨˜ï¼ˆéƒ¨åˆ†ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã¯ç½®æ›ï¼‰
                            if inputText.count < self.transcript.count {
                                // éƒ¨åˆ†ãƒ†ã‚­ã‚¹ãƒˆãŒæ¥ãŸå ´åˆã¯ç½®æ›
                                self.transcript = inputText
                                print("ğŸ“ ConversationController: éƒ¨åˆ†ãƒ†ã‚­ã‚¹ãƒˆæ›´æ–° - ã€Œ\(self.transcript)ã€")
                            } else {
                                // ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆãŒæ¥ãŸå ´åˆã¯ç½®æ›
                                self.transcript = inputText
                                print("âœ… ConversationController: ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆæ›´æ–° - ã€Œ\(self.transcript)ã€")
                            }
                        }
                    } else {
                        // 1ç§’ã«1å›ç¨‹åº¦ã€STTã‚¤ãƒ™ãƒ³ãƒˆãŒæ¥ã¦ã„ãªã„ã“ã¨ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
                        let now = Date()
                        if now.timeIntervalSince(lastLogTime) >= 1.0 {
                            print("âš ï¸ ConversationController: STTã‚¤ãƒ™ãƒ³ãƒˆå¾…æ©Ÿä¸­...ï¼ˆconversation.item.input_audio_transcription.* ã¾ãŸã¯ input_audio_buffer.committed ãŒæ¥ã¦ã„ã¾ã›ã‚“ï¼‰")
                            lastLogTime = now
                        }
                        try await Task.sleep(nanoseconds: 50_000_000)
                    }
                } catch { 
                    // CancellationErrorã¯æ­£å¸¸ãªçµ‚äº†ãªã®ã§ãƒ­ã‚°ã«å‡ºåŠ›ã—ãªã„
                    if !(error is CancellationError) {
                        print("âŒ ConversationController: éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼ - \(error)")
                    }
                    break 
                }
            }
        }

        // è¿”ç­”éŸ³å£°ã®å…ˆå‡ºã—å†ç”Ÿï¼ˆä»»æ„ï¼‰
        receiveAudioTask?.cancel()
        receiveAudioTask = Task { [weak self] in
            guard let self else { return }
            while !Task.isCancelled {
                do {
                    if let chunk = try await self.realtimeClient?.nextAudioChunk() {
                        await MainActor.run { self.isPlayingAudio = true }
                        // âœ… éŸ³å£°å†ç”Ÿã‚’å†é–‹ï¼ˆstopImmediately()ã§volume=0ã«ãªã£ãŸå ´åˆã®å¾©å¸°ï¼‰
                        // æ³¨: onResponseCreatedã§ã‚‚å‘¼ã³å‡ºã—ã¦ã„ã‚‹ãŒã€å¿µã®ãŸã‚ã“ã“ã§ã‚‚å‘¼ã³å‡ºã™
                        self.player.resumeIfNeeded()
                        self.player.playChunk(chunk)
                        await MainActor.run { self.isPlayingAudio = false }
                    } else {
                        try await Task.sleep(nanoseconds: 50_000_000)
                    }
                } catch { 
                    // CancellationErrorã¯æ­£å¸¸ãªçµ‚äº†ãªã®ã§ãƒ­ã‚°ã«å‡ºåŠ›ã—ãªã„
                    if !(error is CancellationError) {
                        print("âŒ ConversationController: éŸ³å£°å†ç”Ÿãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼ - \(error)")
                    }
                    break 
                }
            }
        }
    }
    
    // MARK: - Private Helpers
    private func finishSTTCleanup() {
        sttRequest = nil
        sttTask = nil
        isRecording = false
        let finalText = transcript.trimmingCharacters(in: .whitespacesAndNewlines)
        let userStopped = userStoppedRecording
        userStoppedRecording = false

        // ãƒ¦ãƒ¼ã‚¶ãƒ¼åœæ­¢ or æœ€çµ‚ç¢ºå®šå¾Œã«ã€æœ¬æ–‡ãŒã‚ã‚Œã°AIã¸
        if !finalText.isEmpty, userStopped || !finalText.isEmpty {
            askAI(with: finalText)
        }
    }
    
    private static func isBenignSpeechError(_ error: Error) -> Bool {
        let e = error as NSError
        let msg = e.localizedDescription.lowercased()
        // "canceled""no speech detected" ãªã©ã¯ç„¡å®³æ‰±ã„
        return msg.contains("canceled") || msg.contains("no speech")
        // å¿…è¦ãªã‚‰ã‚³ãƒ¼ãƒ‰ã§åˆ†å²ï¼ˆç’°å¢ƒã§ç•°ãªã‚‹ãŒ 203/216 ã‚’è¦‹ã‚‹ã“ã¨ãŒå¤šã„ï¼‰
        // || e.code == 203 || e.code == 216
    }
    
    // MARK: - AIå‘¼ã³å‡ºã—
    public func askAI(with userText: String) {
        // åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã‚’é€£æŠ•ã—ãªã„
        guard userText != lastAskedText else { return }
        lastAskedText = userText

        aiResponseText = ""              // æ–°ã—ã„ã‚¿ãƒ¼ãƒ³ã®é–‹å§‹
        isThinking = true
        errorMessage = nil

        Task {
            defer { 
                Task { @MainActor in
                    self.isThinking = false 
                }
            }

            // OpenAI Chat Completions
            struct Payload: Encodable {
                let model: String
                let messages: [[String:String]]
                let max_tokens: Int?
                let temperature: Double?
            }
            
            let payload = Payload(
                model: "gpt-4o-mini",
                messages: [
                    ["role": "system", "content": "ã‚ãªãŸã¯å¹¼å…å‘ã‘ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã®ã¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚ã²ã‚‰ãŒãªä¸­å¿ƒãƒ»ä¸€æ–‡ã‚’çŸ­ããƒ»ã‚„ã•ã—ããƒ»ã‚€ãšã‹ã—ã„è¨€è‘‰ã‚’ã•ã‘ã¾ã™ã€‚"],
                    ["role": "user", "content": userText]
                ],
                max_tokens: 120,
                temperature: 0.3
            )

            let endpoint = (Bundle.main.object(forInfoDictionaryKey: "API_BASE") as? String)
                .flatMap(URL.init(string:)) ?? URL(string: "https://api.openai.com/v1")!

            var req = URLRequest(url: endpoint.appendingPathComponent("chat/completions"))
            req.httpMethod = "POST"
            req.addValue("application/json", forHTTPHeaderField: "Content-Type")
            req.addValue("Bearer \(AppConfig.openAIKey)", forHTTPHeaderField: "Authorization")
            req.httpBody = try? JSONEncoder().encode(payload)

            // 429 ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆæœ€å¤§3å›ã€0.5sâ†’1sâ†’2sï¼‰
            var attempt = 0
            let maxAttempts = 3
            var backoff: UInt64 = 500_000_000 // 0.5s

            while attempt < maxAttempts {
                do {
                    let (data, response) = try await URLSession.shared.data(for: req)
                    guard let http = response as? HTTPURLResponse else {
                        throw URLError(.badServerResponse)
                    }

                    if http.statusCode == 429 {
                        // ã‚¨ãƒ©ãƒ¼ãƒœãƒ‡ã‚£ã‚’è§£æã—ã¦æ–‡è¨€åŒ–
                        let msg = Self.readable429Message(from: data)
                        attempt += 1
                        if attempt >= maxAttempts {
                            await MainActor.run {
                                self.errorMessage = msg
                                self.isThinking = false
                            }
                            return
                        }
                        try await Task.sleep(nanoseconds: backoff)
                        backoff *= 2
                        continue
                    }

                    guard (200..<300).contains(http.statusCode) else {
                        // 429 ä»¥å¤–ã®ã‚¨ãƒ©ãƒ¼
                        let body = String(data: data, encoding: .utf8) ?? ""
                        throw NSError(domain: "OpenAI", code: http.statusCode,
                                      userInfo: [NSLocalizedDescriptionKey: "HTTP \(http.statusCode): \(body)"])
                    }

                    struct Choice: Decodable {
                        struct Message: Decodable { let role: String; let content: String }
                        let message: Message
                    }
                    struct Resp: Decodable { let choices: [Choice] }
                    let decoded = try JSONDecoder().decode(Resp.self, from: data)
                    let text = decoded.choices.first?.message.content ?? "(ãŠã¸ã‚“ã˜ãŒã§ããªã‹ã£ãŸã‚ˆ)"

                    await MainActor.run {
                        self.aiResponseText = text
                        self.isThinking = false
                    }
                    return
                } catch {
                    // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾‹å¤–ãªã©
                    await MainActor.run {
                        self.errorMessage = Self.humanReadable(error)
                        self.isThinking = false
                    }
                    return
                }
            }
        }
    }
    
    private static func readable429Message(from data: Data) -> String {
        // OpenAI ã‚¨ãƒ©ãƒ¼å½¢å¼ã«å¯¾å¿œ
        struct OpenAIError: Decodable { 
            struct Inner: Decodable { 
                let message: String
                let type: String?
                let code: String?
            }
            let error: Inner 
        }
        if let e = try? JSONDecoder().decode(OpenAIError.self, from: data) {
            if let code = e.error.code?.lowercased(), code.contains("insufficient_quota") {
                return "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆæ®‹é«˜ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆinsufficient_quotaï¼‰ã€‚è«‹æ±‚/ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            }
            if let code = e.error.code?.lowercased(), code.contains("rate_limit") {
                return "ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤šã™ãã¾ã™ï¼ˆrate limitï¼‰ã€‚å°‘ã—å¾…ã£ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŸã‚ã—ã¦ã­ã€‚"
            }
            return e.error.message
        }
        return "429: ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŸã‚ã—ã¦ã­ã€‚"
    }

    private static func humanReadable(_ error: Error) -> String {
        if let u = error as? URLError {
            switch u.code {
            case .cannotFindHost: return "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ï¼šãƒ›ã‚¹ãƒˆåãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆAPI_BASEã‚’ç¢ºèªï¼‰"
            case .notConnectedToInternet: return "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã«æ¥ç¶šã§ãã¾ã›ã‚“"
            case .userAuthenticationRequired, .userCancelledAuthentication: return "APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ï¼ˆ401ï¼‰"
            default: break
            }
        }
        return error.localizedDescription
    }
    
    // MARK: - ä¿ƒã—ã‚¿ã‚¤ãƒãƒ¼æ©Ÿèƒ½
    
    // âœ… ã€Œå¾…ã¤â†’ä¿ƒã™ã€ã‚¿ã‚¤ãƒãƒ¼å®Ÿè£…
    private func startWaiting() {
        turnState = .waitingUser
        cancelNudge()
        nudgeTimer?.invalidate()
        nudgeTimer = Timer.scheduledTimer(withTimeInterval: 3.0, repeats: false) { [weak self] _ in
            Task { await self?.sendNudge(index: 0) }
        }
    }
    
    private func scheduleNextNudge(_ idx: Int) {
        guard idx < 2 else { return } // æœ€å¤§3å›(0,1,2)ã§åˆ¶é™
        nudgeTimer?.invalidate()
        nudgeTimer = Timer.scheduledTimer(withTimeInterval: 8.0, repeats: false) { [weak self] _ in
            Task { await self?.sendNudge(index: idx + 1) }
        }
    }
    
    private func cancelNudge() {
        nudgeTimer?.invalidate()
        nudgeTimer = nil
    }
    
    private func sendNudge(index: Int) async {
        guard isRealtimeActive else { return }
        // âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—ã¦ã„ã‚‹æœ€ä¸­ã¯ä¿ƒã—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ãªã„
        if case .listening = turnState {
            print("âš ï¸ ConversationController: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—ã¦ã„ã‚‹ãŸã‚ nudge ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            cancelNudge()
            return
        }
        turnState = .nudgedByAI(index)
        await realtimeClient?.nudge(kind: index)
        scheduleNextNudge(index)
    }
}
