//
//  ConversationController.swift
//

import Foundation
import AVFoundation
import Speech
import Domain
import Services
import Support

@MainActor
public final class ConversationController: ObservableObject {

    // MARK: - UI State
    public enum Mode: String, CaseIterable { case localSTT, realtime }

    @Published public var mode: Mode = .localSTT
    @Published public var transcript: String = ""
    @Published public var isRecording: Bool = false
    @Published public var errorMessage: String?
    @Published public var isRealtimeActive: Bool = false
    @Published public var isRealtimeConnecting: Bool = false
    
    // ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    @Published public var aiResponseText: String = ""
    @Published public var isPlayingAudio: Bool = false
    @Published public var hasMicrophonePermission: Bool = false

    // MARK: - Local STT (Speech)
    private let audioEngine = AVAudioEngine()
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "ja-JP"))
    private var sttRequest: SFSpeechAudioBufferRecognitionRequest?
    private var sttTask: SFSpeechRecognitionTask?

    // MARK: - Realtime (OpenAI)
    private let audioSessionManager = AudioSessionManager()
    private var mic: MicrophoneCapture?
    private var player = PlayerNodeStreamer()            // éŸ³å£°å…ˆå‡ºã—ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    private var realtimeClient: RealtimeClientOpenAI?
    private var receiveTextTask: Task<Void, Never>?
    private var receiveAudioTask: Task<Void, Never>?
    private var receiveInputTextTask: Task<Void, Never>?
    private var sessionStartTask: Task<Void, Never>?     // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚¿ã‚¹ã‚¯ã®ç®¡ç†

    // MARK: - Lifecycle
    public init() {}

    deinit {
        Task { @MainActor in
            self.stopLocalTranscription()
            self.stopRealtimeSession()
        }
    }

    // MARK: - Permissions
    public func requestPermissions() {
        AVAudioSession.sharedInstance().requestRecordPermission { [weak self] granted in
            DispatchQueue.main.async {
                self?.hasMicrophonePermission = granted
            }
        }
        SFSpeechRecognizer.requestAuthorization { _ in }
    }

    // MARK: - Local STT (ã¾ãšã¯ã“ã“ã‹ã‚‰)
    public func startLocalTranscription() {
        guard !isRecording else { return }
        guard speechRecognizer?.isAvailable == true else {
            self.errorMessage = "éŸ³å£°èªè­˜ãŒç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
            return
        }

        // 1) AudioSession ã‚’å…ˆã«æ§‹æˆï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ/ãƒ¢ãƒ¼ãƒ‰ã‚’ç¢ºå®šï¼‰
        do { try audioSessionManager.configure() }
        catch {
            self.errorMessage = "AudioSessioné–‹å§‹ã«å¤±æ•—: \(error.localizedDescription)"
            return
        }

        // 2) ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
        let req = SFSpeechAudioBufferRecognitionRequest()
        req.shouldReportPartialResults = true
        self.sttRequest = req
        self.transcript = ""
        self.errorMessage = nil

        // 3) ãƒã‚¤ã‚¯ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¸æµã™ï¼ˆformat: nil ã§è£…ç½®ã®æ­£ã—ã„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«è¿½éšï¼‰
        let input = audioEngine.inputNode
        input.removeTap(onBus: 0)
        input.installTap(onBus: 0, bufferSize: 1024, format: nil) { [weak self] buffer, _ in
            self?.sttRequest?.append(buffer)
        }

        // 4) ã‚¨ãƒ³ã‚¸ãƒ³èµ·å‹•
        do {
            audioEngine.prepare()
            try audioEngine.start()
        } catch {
            self.errorMessage = "AudioEngineé–‹å§‹ã«å¤±æ•—: \(error.localizedDescription)"
            input.removeTap(onBus: 0)
            self.sttRequest = nil
            return
        }

        // 5) èªè­˜ï¼ˆéƒ¨åˆ†ãƒ†ã‚­ã‚¹ãƒˆã‚’éšæ™‚åæ˜ ï¼‰
        sttTask = speechRecognizer?.recognitionTask(with: req) { [weak self] result, err in
            guard let self else { return }
            if let r = result {
                Task { @MainActor in
                    self.transcript = r.bestTranscription.formattedString
                }
            }
            if err != nil || (result?.isFinal == true) {
                Task { @MainActor in self.stopLocalTranscription() }
            }
        }

        isRecording = true
        mode = .localSTT
    }

    public func stopLocalTranscription() {
        guard isRecording || sttTask != nil else { return }
        audioEngine.inputNode.removeTap(onBus: 0)
        audioEngine.stop()
        sttRequest?.endAudio()
        sttTask?.cancel()
        sttRequest = nil
        sttTask = nil
        isRecording = false
    }

    // MARK: - Realtimeï¼ˆæ¬¡ã®æ®µéšï¼šä¼šè©±ï¼‰
    public func startRealtimeSession() {
        // æ—¢ã«æ¥ç¶šä¸­ã¾ãŸã¯æ¥ç¶šæ¸ˆã¿ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
        guard !isRealtimeActive && !isRealtimeConnecting else {
            print("âš ï¸ ConversationController: æ—¢ã«Realtimeã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã¾ãŸã¯æ¥ç¶šä¸­ã§ã™")
            return
        }
        
        // æ—¢å­˜ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        sessionStartTask?.cancel()
        
        // æ¥ç¶šä¸­ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
        isRealtimeConnecting = true
        
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ§‹æˆ
        do { try audioSessionManager.configure() }
        catch { self.errorMessage = "AudioSessionæ§‹æˆã«å¤±æ•—: \(error.localizedDescription)" }

        // ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURLï¼ˆREALTIME_WSS_URL ãŒã‚ã‚Œã°å„ªå…ˆï¼‰
        let url: URL = {
            if let s = Bundle.main.object(forInfoDictionaryKey: "REALTIME_WSS_URL") as? String,
               let u = URL(string: s) { 
                print("ğŸ”— ConversationController: ç›´æ¥URLä½¿ç”¨ - \(s)")
                return u 
            }

            if let https = URL(string: AppConfig.realtimeEndpoint),
               var comps = URLComponents(url: https, resolvingAgainstBaseURL: false) {
                let isHTTP = comps.scheme?.lowercased() == "http"
                comps.scheme = isHTTP ? "ws" : "wss"   // èª­ã¿ã¨æ›¸ãã‚’åˆ†é›¢
                let finalUrl = comps.url ?? https
                print("ğŸ”— ConversationController: æ§‹ç¯‰URLä½¿ç”¨ - \(finalUrl)")
                return finalUrl
            }

            let fallbackUrl = URL(string: "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview")!
            print("ğŸ”— ConversationController: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯URLä½¿ç”¨ - \(fallbackUrl)")
            return fallbackUrl
        }()

        let key = AppConfig.openAIKey
        print("ğŸ”‘ ConversationController: APIã‚­ãƒ¼ç¢ºèª - \(key.prefix(10))...")
        guard !key.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty else {
            self.errorMessage = "OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ï¼ˆSecrets.xcconfig ã‚’ç¢ºèªï¼‰"
            return
        }
        
        // APIã‚­ãƒ¼ã®å½¢å¼ã‚’ãƒã‚§ãƒƒã‚¯
        guard key.hasPrefix("sk-") else {
            self.errorMessage = "APIã‚­ãƒ¼ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ï¼ˆsk-ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰"
            return
        }

        realtimeClient = RealtimeClientOpenAI(url: url, apiKey: key)
        
        // çŠ¶æ…‹å¤‰æ›´ã‚’ç›£è¦–
        realtimeClient?.onStateChange = { [weak self] state in
            Task { @MainActor in
                switch state {
                case .connecting:
                    self?.isRealtimeConnecting = true
                    self?.isRealtimeActive = false
                case .ready:
                    self?.isRealtimeConnecting = false
                    self?.isRealtimeActive = true
                case .closed(let error):
                    self?.isRealtimeConnecting = false
                    self?.isRealtimeActive = false
                    if let error = error {
                        self?.errorMessage = "æ¥ç¶šã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
                    }
                case .idle:
                    self?.isRealtimeConnecting = false
                    self?.isRealtimeActive = false
                default:
                    self?.isRealtimeConnecting = false
                    self?.isRealtimeActive = false
                }
            }
        }
        
        transcript = ""
        aiResponseText = ""
        errorMessage = nil

        sessionStartTask = Task {
            do {
                print("ğŸš€ ConversationController: Realtimeã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹")
                
                // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒ†ã‚¹ãƒˆ
                print("ğŸŒ ConversationController: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒ†ã‚¹ãƒˆä¸­...")
                let testUrl = URL(string: "https://api.openai.com/v1/models")!
                var testRequest = URLRequest(url: testUrl)
                testRequest.addValue("Bearer \(key)", forHTTPHeaderField: "Authorization")
                testRequest.timeoutInterval = 10
                
                let (_, response) = try await URLSession.shared.data(for: testRequest)
                if let httpResponse = response as? HTTPURLResponse {
                    print("ğŸŒ ConversationController: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆçµæœ - Status: \(httpResponse.statusCode)")
                    if httpResponse.statusCode == 401 {
                        await MainActor.run {
                            self.errorMessage = "APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ï¼ˆ401 Unauthorizedï¼‰"
                            self.isRealtimeConnecting = false
                        }
                        return
                    }
                }
                
                try await realtimeClient?.startSession(child: ChildProfile.sample(), context: [])
                print("âœ… ConversationController: ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æˆåŠŸ")
                
                // çŠ¶æ…‹ã‚’æ›´æ–°
                await MainActor.run {
                    self.isRealtimeConnecting = false
                    self.isRealtimeActive = true
                    self.mode = .realtime
                    self.startReceiveLoops()
                }
            } catch {
                print("âŒ ConversationController: ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹å¤±æ•— - \(error.localizedDescription)")
                await MainActor.run {
                    if let urlError = error as? URLError {
                        switch urlError.code {
                        case .notConnectedToInternet:
                            self.errorMessage = "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒã‚ã‚Šã¾ã›ã‚“"
                        case .timedOut:
                            self.errorMessage = "æ¥ç¶šãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
                        case .cannotConnectToHost:
                            self.errorMessage = "ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“"
                        default:
                            self.errorMessage = "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: \(urlError.localizedDescription)"
                        }
                    } else {
                        self.errorMessage = "Realtimeæ¥ç¶šå¤±æ•—: \(error.localizedDescription)"
                    }
                    self.isRealtimeConnecting = false
                    self.isRealtimeActive = false
                }
            }
        }
    }

    public func stopRealtimeSession() {
        print("ğŸ›‘ ConversationController: Realtimeã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†")
        
        // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        sessionStartTask?.cancel()
        sessionStartTask = nil
        
        receiveTextTask?.cancel(); receiveTextTask = nil
        receiveAudioTask?.cancel(); receiveAudioTask = nil
        receiveInputTextTask?.cancel(); receiveInputTextTask = nil
        mic?.stop(); mic = nil
        player.stop()
        isRecording = false
        isRealtimeActive = false
        isRealtimeConnecting = false
        
        Task {
            try? await realtimeClient?.finishSession()
            await MainActor.run {
                self.realtimeClient = nil
            }
        }
    }

    public func startPTTRealtime() {
        guard let client = realtimeClient else { 
            self.errorMessage = "Realtimeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            return 
        }
        mic?.stop()
        mic = MicrophoneCapture { buf in
            Task { try? await client.sendMicrophonePCM(buf) }
        }
        do { 
            try mic?.start()
            isRecording = true
            transcript = "" // éŒ²éŸ³é–‹å§‹æ™‚ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
        }
        catch { 
            self.errorMessage = "ãƒã‚¤ã‚¯é–‹å§‹ã«å¤±æ•—: \(error.localizedDescription)"
            isRecording = false
        }
    }

    public func stopPTTRealtime() {
        isRecording = false
        mic?.stop()
        Task {
            // interrupt ã‹ã‚‰ commitAndRequestResponse ã«å¤‰æ›´
            try? await realtimeClient?.commitAndRequestResponse()
        }
    }

    private func startReceiveLoops() {
        // è¿”ç­”ãƒ†ã‚­ã‚¹ãƒˆï¼ˆpartialï¼‰ãƒ«ãƒ¼ãƒ—
        receiveTextTask?.cancel()
        receiveTextTask = Task { [weak self] in
            guard let self else { return }
            while !Task.isCancelled {
                do {
                    if let part = try await self.realtimeClient?.nextPartialText() {
                        await MainActor.run { 
                            // AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½è¨˜
                            if self.aiResponseText.isEmpty { 
                                self.aiResponseText = part 
                            } else { 
                                self.aiResponseText += part   // â† è¿½è¨˜
                            }
                        }
                    } else {
                        try await Task.sleep(nanoseconds: 50_000_000) // idle 50ms
                    }
                } catch { break }
            }
        }

        // éŸ³å£°å…¥åŠ›ã®ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
        receiveInputTextTask?.cancel()
        receiveInputTextTask = Task { [weak self] in
            guard let self else { return }
            while !Task.isCancelled {
                do {
                    if let inputText = try await self.realtimeClient?.nextInputText() {
                        await MainActor.run { 
                            self.transcript = inputText
                        }
                    } else {
                        try await Task.sleep(nanoseconds: 50_000_000)
                    }
                } catch { break }
            }
        }

        // è¿”ç­”éŸ³å£°ã®å…ˆå‡ºã—å†ç”Ÿï¼ˆä»»æ„ï¼‰
        receiveAudioTask?.cancel()
        receiveAudioTask = Task { [weak self] in
            guard let self else { return }
            while !Task.isCancelled {
                do {
                    if let chunk = try await self.realtimeClient?.nextAudioChunk() {
                        await MainActor.run { self.isPlayingAudio = true }
                        self.player.playChunk(chunk)
                        await MainActor.run { self.isPlayingAudio = false }
                    } else {
                        try await Task.sleep(nanoseconds: 50_000_000)
                    }
                } catch { break }
            }
        }
    }
}
