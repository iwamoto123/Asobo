//
//  ConversationController.swift
//

import Foundation
import AVFoundation
import Speech
import Domain
import Services
import Support
import DataStores
import Network
#if canImport(UIKit)
import UIKit
#endif

@MainActor
public final class ConversationController: NSObject, ObservableObject {

    // MARK: - UI State
    public enum Mode: String, CaseIterable { case localSTT, realtime }

    // âœ… æ©Ÿèƒ½ãƒˆã‚°ãƒ«
    public static let localSTTEnabled: Bool = true
    public var isLocalSTTEnabled: Bool { Self.localSTTEnabled }

    @Published public var mode: Mode = .localSTT
    @Published public var transcript: String = ""
    /// å±¥æ­´/ãƒ­ã‚°ã«ç©ã‚€ã®ã¨åŒã˜ã€Œç¢ºå®šãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ãƒ†ã‚­ã‚¹ãƒˆã€ã€‚
    /// Homeã®ãƒ¢ãƒ‹ã‚¿ãƒ¼è¡¨ç¤ºãªã©ã€"æ­£ç¢ºãªç¢ºå®šæ–‡" ã‚’å‡ºã—ãŸã„ç®‡æ‰€ã§ä½¿ç”¨ã™ã‚‹ã€‚
    @Published public var lastCommittedUserText: String = ""
    @Published public var isRecording: Bool = false
    @Published public var errorMessage: String?
    @Published public var isRealtimeActive: Bool = false
    @Published public var isRealtimeConnecting: Bool = false
    // âœ… éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®ãƒ­ãƒ¼ã‚«ãƒ«æ–‡å­—èµ·ã“ã—ã‚’è¡Œã†ã‹ï¼ˆç«¯æœ«ç’°å¢ƒã§ kAFAssistantErrorDomain 1101 ãŒå¤šç™ºã™ã‚‹ãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆOFFï¼‰
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    let enableLocalUserTranscription: Bool = ConversationController.localSTTEnabled

    // MARK: - AudioMissing mitigation
    /// `gpt-4o-audio-preview` ãŒã€Œãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼ˆaudioMissing=trueï¼‰ã€ã§è¿”ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€
    /// ç›´è¿‘ã®é€£ç¶šå›æ•°ã‚’æ•°ãˆã¦ systemPrompt ã«ãƒ–ãƒ¼ã‚¹ãƒˆæŒ‡ç¤ºã‚’å…¥ã‚Œã‚‹ã€‚
    // NOTE: extensionãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var audioMissingConsecutiveCount: Int = 0

    // è¿½åŠ : ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒåœæ­¢ã—ãŸã‹ã‚’è¦šãˆã‚‹ãƒ•ãƒ©ã‚°
    private var userStoppedRecording = false

    // âœ… AIéŸ³å£°å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°ï¼ˆonAudioDeltaReceivedã§è¨­å®šã€sendMicrophonePCMã®æ—©æœŸreturnã‚’ä¸€å…ƒåŒ–ï¼‰
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    @Published var isAIPlayingAudio: Bool = false
    // âœ… ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ãƒ¢ãƒ¼ãƒ‰ã®æœ‰åŠ¹åŒ–ãƒ•ãƒ©ã‚°
    @Published public var isHandsFreeMode: Bool = false

    // âœ… ã‚¿ãƒ¼ãƒ³çŠ¶æ…‹ï¼ˆæ‹¡å¼µç‰ˆï¼‰
    enum TurnState: Equatable {
        case idle               // ã‚»ãƒƒã‚·ãƒ§ãƒ³å‰ or çµ‚äº†å¾Œ
        case waitingUser        // åˆå›/æ¯ã‚¿ãƒ¼ãƒ³ï¼šã¾ãšãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å£°ã‚’å¾…ã¤
        case nudgedByAI(Int)   // ä¿ƒã—(ä½•å›ç›®ã‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)
        case listening          // VADãŒ speech_started ã€œ speech_stopped ã®é–“
        case thinking           // commit æ¸ˆã¿ã€œå¿œç­”ç”Ÿæˆä¸­
        case speaking           // AIãŒTTSå‡ºåŠ›ä¸­
        case clarifying         // èãå–ã‚Šä¸å¯â†’èãè¿”ã—ä¸­
    }
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰çŠ¶æ…‹æ›´æ–°ã™ã‚‹ãŸã‚ internal(set) ç›¸å½“ï¼ˆ=åˆ¶é™ãªã—ï¼‰ã«ã™ã‚‹
    @Published var turnState: TurnState = .idle

    // âœ… ã€Œå¾…ã¤â†’ä¿ƒã™ã€ã‚¿ã‚¤ãƒãƒ¼
    private var nudgeTimer: Timer?
    // âœ… ä¿ƒã—å›æ•°ã®ä¸Šé™ã¨ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    private let maxNudgeCount = AppConfig.nudgeMaxCount
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    var nudgeCount = 0

    // âœ… è¿½åŠ : æœ€å¾Œã«ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å£°ï¼ˆç’°å¢ƒéŸ³å«ã‚€ï¼‰ã€ãŒé–¾å€¤ã‚’è¶…ãˆãŸæ™‚åˆ»
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    var lastUserVoiceActivityTime: Date = Date()
    var lastInputRMS: Double?

    /// ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šç›´è¿‘ã®å…¥åŠ›RMS(dB)ã€‚VADåˆ¶å¾¡ã¨ã¯ç‹¬ç«‹ã«ã€Œè¦³æ¸¬ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã€ã§å‚ç…§ã™ã‚‹ã€‚
    public var debugLastInputRmsDb: Double? { lastInputRMS }
    /// ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šé–‹å§‹/çµ‚äº†ã®RMSé–¾å€¤ï¼ˆå…¥åŠ›ãƒ«ãƒ¼ãƒˆã§å¤‰åŒ–ã—å¾—ã‚‹ã®ã§ãƒ­ã‚°ç”¨ã«å…¬é–‹ï¼‰
    public var debugActiveRmsStartThresholdDb: Double { activeRmsStartThresholdDb }
    public var debugActiveSpeechEndRmsThresholdDb: Double { activeSpeechEndRmsThresholdDb }

    // âœ… è¿½åŠ : ç„¡éŸ³åˆ¤å®šã®é–¾å€¤ï¼ˆ-50dBã‚ˆã‚Šå¤§ãã‘ã‚Œã°ã€Œä½•ã‹éŸ³ãŒã—ã¦ã„ã‚‹ã€ã¨ã¿ãªã™ï¼‰
    // èª¿æ•´ç›®å®‰: -40dB(æ™®é€š) ã€œ -60dB(é™å¯‚)ã€‚-50dBã¯ã€Œã•ã•ã‚„ãå£°ã‚„ç’°å¢ƒéŸ³ã€ãƒ¬ãƒ™ãƒ«
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    let silenceThresholdDb: Double = -50.0

    // âœ… è¿½åŠ : speech_startedãŒæ¥ã¦ã„ãªã„è­¦å‘Šã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    private var speechStartedMissingCount: Int = 0

    // MARK: - VAD (Hands-free Conversation)
    enum VADState { case idle, speaking }
    // ğŸ”§ Temporarily extremely low thresholds to force VAD triggering
    // ğŸ”§ Loosened thresholds to verify sensitivity (see VAD logging)
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    let speechStartThreshold: Float = 0.005
    let speechEndThreshold: Float = 0.002
    let defaultRmsStartThresholdDb: Double = -40.0
    // Bluetooth/HFPã¯å…¥åŠ›ãƒ¬ãƒ™ãƒ«ãŒå°ã•ã‚/ã°ã‚‰ã¤ãã‚„ã™ã„ã®ã§ã€é–‹å§‹åˆ¤å®šã‚’å°‘ã—ç”˜ãã™ã‚‹ï¼ˆã‚ˆã‚Šè² ã®å€¤ã«ã™ã‚‹ã¨é–‹å§‹ã—ã‚„ã™ã„ï¼‰
    let bluetoothRmsStartThresholdDb: Double = -45.0
    // âœ… ç™ºè©±çµ‚äº†å´ã®RMSé–¾å€¤ï¼ˆdBFSï¼‰
    // iPhoneå†…è”µãƒã‚¤ã‚¯ + VoiceChat/VoiceProcessing ã ã¨é™ã‹ãªç’°å¢ƒã§ã‚‚ãƒã‚¤ã‚ºãƒ•ãƒ­ã‚¢ãŒ -45ã€œ-50dB ä»˜è¿‘ã«å¼µã‚Šä»˜ãã“ã¨ãŒã‚ã‚Šã€
    // -55dBã‚’è¦æ±‚ã™ã‚‹ã¨ã€Œç„¡éŸ³ã«ãªã‚‰ãªã„ã€æ‰±ã„ã§ speaking ãŒçµ‚ã‚ã‚‰ãªã„ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€å°‘ã—é«˜ã‚ã«ã™ã‚‹ã€‚
    let defaultSpeechEndRmsThresholdDb: Double = -50.0
    // Bluetooth/HFPã¯ãƒã‚¤ã‚ºãƒ•ãƒ­ã‚¢ãŒé«˜ãã€-55dBæœªæº€ã«è½ã¡ã«ãã„ãŸã‚çµ‚äº†ã§ããšspeakingå¼µã‚Šä»˜ãã«ãªã‚Šã‚„ã™ã„
    let bluetoothSpeechEndRmsThresholdDb: Double = -45.0
    let defaultMinSilenceDuration: TimeInterval = 1.2
    let bluetoothMinSilenceDuration: TimeInterval = 1.2
    let speechStartHoldDuration: TimeInterval = 0.15
    let minSpeechDuration: TimeInterval = 0.25
    // âœ… å‰²ã‚Šè¾¼ã¿åˆ¤å®šç”¨ï¼ˆSilero VADã‚’ä¸€å®šæ™‚é–“é€£ç¶šæ¤œå‡ºã—ãŸå ´åˆã®ã¿åœæ­¢ï¼‰
    let bargeInVADThreshold: Float = 0.5
    let bargeInHoldDuration: TimeInterval = 0.15  // 150ms ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹
    var vadInterruptSpeechStart: Date?
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internal(set) ç›¸å½“ï¼ˆ=åˆ¶é™ãªã—ï¼‰ã«ã™ã‚‹
    @Published var vadState: VADState = .idle
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var speechStartTime: Date?
    var silenceTimer: Timer?
    var isUserSpeaking: Bool = false
    var speechStartCandidateTime: Date?
    // âœ… VADç¢ºç‡(prob)ãŒå£Šã‚Œã¦å¸¸ã«ä½ã„/å¼µã‚Šä»˜ãå ´åˆã€çµ‚äº†åˆ¤å®šã«ä½¿ã†ã¨å³çµ‚äº†ã—å¾—ã‚‹ã€‚
    //    ã€Œé–‹å§‹ãŒprobã§ãƒˆãƒªã‚¬ã•ã‚Œã¦ã„ãªã„ã€ã‚¿ãƒ¼ãƒ³ã§ã¯ã€çµ‚äº†åˆ¤å®šã§ã¯probã‚’ä¿¡ç”¨ã—ãªã„ã€‚
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var speechStartTriggeredByProb: Bool = false

    // MARK: - STT-based VAD (New policy)
    // SileroVAD/RMSã¯æ¸¬å®šãƒ»å¯è¦–åŒ–ç”¨é€”ã¨ã—ã¦æ®‹ã™ãŒã€ç™ºè©±é–‹å§‹/çµ‚äº†ã®åˆ¤å®šã¯ãƒ©ã‚¤ãƒ–STTã§è¡Œã†
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    let sttVADSpeechStartMinChars: Int = 1
    let sttVADEndSilenceDuration: TimeInterval = 1.5
    var sttVADEndTimer: Timer?

    // MARK: - Hands-free Realtime STT Monitor (for end-of-speech fallback)
    // ã€Œãƒ†ã‚­ã‚¹ãƒˆåŒ–ã‚’æ¤œçŸ¥å¾Œã€é›‘éŸ³ãªã©ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã§ããªã„ã‚‚ã®ãŒç¶šã„ãŸã‚‰ç™ºè©±çµ‚äº†ã€ç”¨
    // âœ… STTãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®çŒ¶äºˆï¼ˆsttStagnation / sttNoText ã‚’çµ±ä¸€ï¼‰
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    let sttFallbackDuration: TimeInterval = 3.0
    var sttStagnationDuration: TimeInterval { sttFallbackDuration }
    let sttStagnationMinChars: Int = 2
    // ã€Œãƒ†ã‚­ã‚¹ãƒˆãŒå…¨ãå‡ºãªã„ã¾ã¾ã€éŸ³ã ã‘ãŒç¶šãï¼ˆéŸ³æ¥½/é›‘éŸ³ï¼‰ã€ã‚±ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var sttNoTextDuration: TimeInterval { sttFallbackDuration }

    // âœ… çŠ¶æ…‹ãƒ¢ãƒ‹ã‚¿ãƒ¼ç”¨ï¼šãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ä¸¦èµ°STTã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
    @Published public var handsFreeMonitorTranscript: String = ""
    @Published public var handsFreeMonitorStatus: String = "off" // off / running / error
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    let handsFreeMonitorUIUpdateMinInterval: TimeInterval = 0.15
    var handsFreeMonitorLastUIUpdateAt: Date?

    // âœ… SpeechEndå¾Œã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é€ä¿¡ç”¨ï¼ˆLocal STTãŒç©ºã®ã¨ãã«ä½¿ã†ï¼‰
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var handsFreeMonitorFinalCandidate: String = ""

    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var handsFreeSTTRequest: SFSpeechAudioBufferRecognitionRequest?
    var handsFreeSTTTask: SpeechRecognitionTasking?
    var handsFreeSTTLastNormalized: String = ""
    var handsFreeSTTLastChangeAt: Date?
    var handsFreeSTTRestartTask: Task<Void, Never>?
    var handsFreeSTTLastAutoStartAt: Date?
    // ãƒãƒ¼ã‚¸ã‚¤ãƒ³æ¤œçŸ¥å°‚ç”¨ã®ã€Œå‰å›ãƒ†ã‚­ã‚¹ãƒˆã€ã€‚AIå†ç”Ÿé–‹å§‹æ™‚/å‰²ã‚Šè¾¼ã¿å¾Œã«ãƒªã‚»ãƒƒãƒˆã—ã¦å–ã‚Šã“ã¼ã—ã‚’æ¸›ã‚‰ã™ã€‚
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var handsFreeBargeInLastNormalized: String = ""
    var handsFreeSTTAppendCount: UInt64 = 0
    var handsFreeSTTLastAppendLogAt: Date?

    // MARK: - STT-based Barge-in (while AI speaking)
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var aiPlaybackStartedAt: Date?
    var lastSTTBargeInAt: Date?
    let sttBargeInIgnoreWindowAfterPlaybackStart: TimeInterval = 0.2
    let sttBargeInMinInterval: TimeInterval = 0.8
    let sttBargeInMinChars: Int = 2

    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    var isBluetoothInput: Bool {
        let session = AVAudioSession.sharedInstance()
        return session.currentRoute.inputs.contains { $0.portType == .bluetoothHFP }
    }
    var activeRmsStartThresholdDb: Double {
        isBluetoothInput ? bluetoothRmsStartThresholdDb : defaultRmsStartThresholdDb
    }
    var activeSpeechEndRmsThresholdDb: Double {
        isBluetoothInput ? bluetoothSpeechEndRmsThresholdDb : defaultSpeechEndRmsThresholdDb
    }
    var activeMinSilenceDuration: TimeInterval {
        isBluetoothInput ? bluetoothMinSilenceDuration : defaultMinSilenceDuration
    }

    // âœ… å„ã‚¿ãƒ¼ãƒ³ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·è¨ˆæ¸¬ç”¨
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    struct TurnMetrics {
        var listenStart: Date?
        var speechEnd: Date?
        var requestStart: Date?
        var firstByte: Date?
        var firstAudio: Date?
        var firstText: Date?
        var streamComplete: Date?
        var playbackEnd: Date?
    }
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var turnMetrics = TurnMetrics()

    // ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    @Published public var aiResponseText: String = ""
    @Published public var isPlayingAudio: Bool = false
    @Published public var hasMicrophonePermission: Bool = false
    @Published public var liveSummary: String = ""                 // ä¼šè©±ã®ç°¡æ˜“è¦ç´„ï¼ˆæ¯ã‚¿ãƒ¼ãƒ³æ›´æ–°ï¼‰
    @Published public var liveInterests: [FirebaseInterestTag] = [] // ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«æ›´æ–°
    @Published public var liveNewVocabulary: [String] = []          // ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«æ›´æ–°
    // âœ… å‰²ã‚Šè¾¼ã¿å¾Œã«æµå…¥ã™ã‚‹å¤ã„AIãƒãƒ£ãƒ³ã‚¯ã‚’ç„¡è¦–ã™ã‚‹ãŸã‚ã®ã‚²ãƒ¼ãƒˆ
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var ignoreIncomingAIChunks: Bool = false
    var currentTurnId: Int = 0         // ã‚¿ãƒ¼ãƒ³ã®ä¸–ä»£IDï¼ˆå˜ä¸€ã®çœŸå®Ÿï¼‰
    var listeningTurnId: Int = 0       // VAD/éŒ²éŸ³ç”¨ã®ä¸–ä»£ID
    var playbackTurnId: Int?           // å†ç”ŸçŠ¶æ…‹é€šçŸ¥ã®ä¸–ä»£ID

    // AIå‘¼ã³å‡ºã—ç”¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    @Published public var isThinking: Bool = false   // ãã‚‹ãã‚‹è¡¨ç¤ºç”¨
    private var lastAskedText: String = ""           // åŒæ–‡ã®é€£æŠ•é˜²æ­¢

    // MARK: - Local STT (Speech) - DIå¯¾å¿œ
    private let audioEngine = AVAudioEngine()
    private let audioSession: AudioSessionManaging
    /// ç¢ºå®šç”¨ï¼ˆPTT/éŒ²éŸ³å¾Œã®ãƒ­ãƒ¼ã‚«ãƒ«STTï¼‰
    private let speech: SpeechRecognizing
    /// ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ç›£è¦–ç”¨ï¼ˆãƒãƒ¼ã‚¸ã‚¤ãƒ³/ãƒ©ã‚¤ãƒ–è¡¨ç¤ºï¼‰
    /// iOSã§ã¯åŒä¸€recognizerã§è¤‡æ•°taskã‚’å›ã™ã¨ã‚­ãƒ£ãƒ³ã‚»ãƒ«ç«¶åˆã—ã‚„ã™ã„ã®ã§åˆ†ã‘ã‚‹
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    let handsFreeSpeech: SpeechRecognizing
    private var sttRequest: SFSpeechAudioBufferRecognitionRequest?
    private var sttTask: SpeechRecognitionTasking?

    // MARK: - Realtime (OpenAI)
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    let audioSessionManager = AudioSessionManager()
    // âœ… AECæœ‰åŠ¹åŒ–ã®ãŸã‚ã€å…±é€šã®AVAudioEngineã‚’ä½¿ç”¨
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    let sharedAudioEngine = AVAudioEngine()
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    var mic: MicrophoneCapture?
    // NOTE: extensionãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var player: PlayerNodeStreamer            // éŸ³å£°å…ˆå‡ºã—ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    // âœ… Realtime API ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ã€gpt-4o-audio-preview ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã«åˆ‡ã‚Šæ›¿ãˆ
    private var realtimeClient: RealtimeClientOpenAI?
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    var audioPreviewClient: AudioPreviewStreamingClient?
    // NOTE: extensionãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var recordedPCMData = Data()
    var recordedSampleRate: Double = 24_000
    // âœ… ç›¸æ§Œå†ç”ŸON/OFFï¼ˆå½“é¢OFFã«ã™ã‚‹ï¼‰
    // NOTE: extensionãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    let enableFillers = true
    // âœ… å†ç”Ÿã™ã‚‹ç›¸æ§Œãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆï¼ˆãƒãƒ³ãƒ‰ãƒ«ã«è¿½åŠ ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
    // NOTE: extensionãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    let fillerFiles = [
        "ã†ã‚“ã†ã‚“", "ãã£ã‹", "ãµãƒ¼ã‚“", "ã¸ãƒ¼"
    ]
    // âœ… ç›¸æ§Œå†ç”Ÿä¸­ã‹ã®ãƒ•ãƒ©ã‚°ï¼ˆAIéŸ³å£°ãŒæ¥ãŸã‚‰ä¸€åº¦ã ã‘æ­¢ã‚ã‚‹ï¼‰
    // NOTE: extensionãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var isFillerPlaying = false

    // âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯TTSæ™‚ã ã‘ã€Œãƒã‚¹ã‚³ãƒƒãƒˆå£°ã€ã‚’å¼·ã‚ã«ã—ã¦ã€çµ‚ã‚ã£ãŸã‚‰å…ƒã«æˆ»ã™
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var fallbackTTSVoiceFXRestore: PlayerNodeStreamer.VoiceFXState?
    var isFallbackTTSPlaybackActive: Bool = false
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    var receiveTextTask: Task<Void, Never>?
    var receiveAudioTask: Task<Void, Never>?
    var receiveInputTextTask: Task<Void, Never>?
    var sessionStartTask: Task<Void, Never>?     // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚¿ã‚¹ã‚¯ã®ç®¡ç†
    var liveSummaryTask: Task<Void, Never>?      // ãƒ©ã‚¤ãƒ–è¦ç´„ç”Ÿæˆã‚¿ã‚¹ã‚¯
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var inMemoryTurns: [FirebaseTurn] = []       // ä¼šè©±ãƒ­ã‚°ï¼ˆè¦ç´„ç”¨ï¼‰
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    var routeChangeObserver: Any?
    
    // MARK: - App lifecycle / background keep-alive
    var lifecycleObserverTokens: [NSObjectProtocol] = []
    #if canImport(UIKit)
    var backgroundTaskId: UIBackgroundTaskIdentifier = .invalid
    #endif
    /// ä»–ã‚¢ãƒ—ãƒªï¼ˆYouTubeç­‰ï¼‰ã«ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’å¥ªã‚ã‚Œã¦ `shouldResume=false` ã«ãªã£ãŸå ´åˆã«ã€
    /// ãƒ•ã‚©ã‚¢ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å¾©å¸°æ™‚ã«è‡ªå‹•ã§ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ã‚’å¾©æ—§ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°ã€‚
    var needsHandsFreeRecoveryOnForeground: Bool = false

    // MARK: - Fallback TTS tuning (audio-only; UIãƒ†ã‚­ã‚¹ãƒˆã¯å¤‰ãˆãªã„)
    /// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯TTSã®éŸ³å£°ã¯ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆå´ã®è»½ã„æ•´å½¢ã¨å†ç”Ÿå´ã®Voice FXã§ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’èª¿æ•´ã™ã‚‹ã€‚

    /// gpt-4o-audio-preview ã«æ¸¡ã™ user ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…ˆé ­ã®å…±é€šãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã€‚
    /// - Note: systemPrompt ã¨ã¯åˆ¥ã«ã€user å´ã«ã‚‚ã€Œå¿…ãšéŸ³å£°ã‚’è¿”ã™ã€æŒ‡ç¤ºã‚’æ¯å›ä»˜ä¸ã™ã‚‹ï¼ˆéŸ³å£°æ¬ è½ã®å†ç™ºã‚’æŠ‘ãˆã‚‹ç›®çš„ï¼‰ã€‚
    var audioPreviewUserMessagePrefix: String {
        """
        ã€é‡è¦ã€‘
        - è¿”ç­”ã¯å¿…ãšéŸ³å£°ï¼ˆaudioï¼‰ã‚’å«ã‚ã¦ãã ã•ã„ã€‚ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã®è¿”ç­”ã¯ç¦æ­¢ã§ã™ã€‚
        - å‡ºåŠ›ã¯ã€Œaudio voice=nova, format=pcm16ã€ã§ã€å¿…ãš audio ãƒãƒ£ãƒ³ã‚¯ã‚’é€ã£ã¦ãã ã•ã„ã€‚

        """
    }

    // âœ… ä¼šè©±æ–‡è„ˆï¼ˆéå»ã®ãƒ†ã‚­ã‚¹ãƒˆå±¥æ­´ï¼‰ã‚’ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹APIã«æ¸¡ã™ãŸã‚ã«ä¿æŒ
    struct HistoryItem: Codable {
        let role: String    // "user" or "assistant"
        let text: String
    }
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    var conversationHistory: [HistoryItem] = []

    // MARK: - Firebaseä¿å­˜
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    let firebaseRepository = FirebaseConversationsRepository()
    var currentSessionId: String?
    // âœ… èªè¨¼æƒ…å ±ï¼ˆAuthViewModelã‹ã‚‰è¨­å®šã•ã‚Œã‚‹ï¼‰
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var currentUserId: String?
    var currentChildId: String?
    private var currentChildName: String?
    private var currentChildNickname: String?
    /// Homeãªã©ã®UIã‹ã‚‰ã€Œä»Šã¯ã“ã®åå‰ã‚’å„ªå…ˆã—ã¦å‘¼ã‚“ã§ã»ã—ã„ã€ã‚’æŒ‡å®šã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
    /// - Note: ã“ã“ã§æŒ‡å®šã•ã‚ŒãŸå ´åˆã€systemPromptå´ã§å„ªå…ˆçš„ã«å‘¼ã³ã‹ã‘ã‚‹ã‚ˆã†æŒ‡ç¤ºã™ã‚‹
    var preferredCallNameOverride: String?
    /// ãã‚‡ã†ã ã„ãŒã„ã‚‹å ´åˆã«ã€Œã„ã¾è©±ã—ã¦ã„ã‚‹ã®ã¯ã“ã®å­ã€ã‚’UIã‹ã‚‰ä¸€æ™‚æŒ‡å®šã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã€‚
    /// - Note: Firestoreä¸Šã®ä¿å­˜ãƒ‘ã‚¹(childId)ã¯å¤‰ãˆãšã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ¡ã‚¿æƒ…å ±ã¨ã—ã¦ä¿å­˜ã—ã¦å±¥æ­´è¡¨ç¤ºã«ä½¿ã†ã€‚
    var speakerChildIdOverride: String?
    var speakerChildNameOverride: String?
    /// éŒ²éŸ³ä¸­ã«æŠ¼ã•ã‚Œã¦ã„ãŸã€Œè©±è€…ï¼ˆå­ï¼‰ã€ã‚’ã€ã“ã®ã‚¿ãƒ¼ãƒ³ã®ä¿å­˜ã«ç¢ºå®Ÿã«åæ˜ ã™ã‚‹ãŸã‚ã®ãƒ­ãƒƒã‚¯ã€‚
    /// - Note: ãƒœã‚¿ãƒ³ãŒé›¢ã•ã‚Œã¦ã‚‚ã€éŒ²éŸ³ä¸­ã«æŠ¼ã•ã‚Œã¦ã„ãŸäº‹å®Ÿã‚’ä¿æŒã—ãŸã„ã€‚
    var lockedSpeakerChildIdForTurn: String?
    var lockedSpeakerChildNameForTurn: String?
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‚ç…§/æ›´æ–°ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    var turnCount: Int = 0

    // ä¼šè©±ã§å‘¼ã¶åå‰ï¼ˆãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ å„ªå…ˆï¼‰
    // NOTE: extensionãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‚ç…§ã™ã‚‹ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    var childCallName: String? {
        if let nickname = currentChildNickname?.trimmingCharacters(in: .whitespacesAndNewlines), !nickname.isEmpty {
            return nickname
        }
        if let name = currentChildName?.trimmingCharacters(in: .whitespacesAndNewlines), !name.isEmpty {
            return name
        }
        return nil
    }

    /// systemPromptã§ä½¿ã†å‘¼ã³åï¼ˆUIæŒ‡å®šã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆï¼‰
    var effectiveCallName: String? {
        if let override = preferredCallNameOverride?.trimmingCharacters(in: .whitespacesAndNewlines),
           !override.isEmpty {
            return override
        }
        return childCallName
    }

    /// Homeã®åå‰ãƒœã‚¿ãƒ³ãªã©ã‹ã‚‰å‘¼ã³å‡ºã™
    public func setPreferredCallNameOverride(_ name: String?) {
        let trimmed = name?.trimmingCharacters(in: .whitespacesAndNewlines)
        preferredCallNameOverride = (trimmed?.isEmpty == true) ? nil : trimmed
    }

    /// Homeã®ã€Œãã‚‡ã†ã ã„åå‰ãƒœã‚¿ãƒ³ï¼ˆæŠ¼ã—ã¦ã„ã‚‹é–“ã ã‘æœ‰åŠ¹ï¼‰ã€ãªã©ã‹ã‚‰å‘¼ã³å‡ºã™
    /// - Note: ã“ã“ã§æŒ‡å®šã•ã‚ŒãŸå€¤ã¯ Firestore ã® session ã«ãƒ¡ã‚¿æƒ…å ±ã¨ã—ã¦ä¿å­˜ã—ã€å±¥æ­´ã‚«ãƒ¼ãƒ‰è¡¨ç¤ºã§ä½¿ã†ã€‚
    public func setSpeakerAttributionOverride(childId: String?, childName: String?) {
        let trimmedId = childId?.trimmingCharacters(in: .whitespacesAndNewlines)
        let trimmedName = childName?.trimmingCharacters(in: .whitespacesAndNewlines)
        speakerChildIdOverride = (trimmedId?.isEmpty == true) ? nil : trimmedId
        speakerChildNameOverride = (trimmedName?.isEmpty == true) ? nil : trimmedName

        // éŒ²éŸ³ä¸­ãªã‚‰ã€ã“ã®ã‚¿ãƒ¼ãƒ³ã«ç´ä»˜ãå€¤ã¨ã—ã¦ãƒ­ãƒƒã‚¯ã™ã‚‹ï¼ˆæŠ¼ä¸‹ãŒé›¢ã‚Œã¦ã‚‚ä¿æŒï¼‰
        if isRecording {
            if let id = speakerChildIdOverride, let name = speakerChildNameOverride {
                lockedSpeakerChildIdForTurn = id
                lockedSpeakerChildNameForTurn = name
            }
        }
    }

    // âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’è¨­å®šã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰
    public func setupUser(userId: String, childId: String, childName: String? = nil, childNickname: String? = nil) {
        self.currentUserId = userId
        self.currentChildId = childId
        let trimmedName = childName?.trimmingCharacters(in: .whitespacesAndNewlines)
        let trimmedNickname = childNickname?.trimmingCharacters(in: .whitespacesAndNewlines)
        self.currentChildName = trimmedName?.isEmpty == true ? nil : trimmedName
        self.currentChildNickname = trimmedNickname?.isEmpty == true ? nil : trimmedNickname
        // childãŒåˆ‡ã‚Šæ›¿ã‚ã£ãŸã‚‰ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã¯ãƒªã‚»ãƒƒãƒˆï¼ˆåˆ¥ã®å­ã«å¼•ããšã‚‰ãªã„ï¼‰
        self.preferredCallNameOverride = nil
        self.speakerChildIdOverride = nil
        self.speakerChildNameOverride = nil
        self.lockedSpeakerChildIdForTurn = nil
        self.lockedSpeakerChildNameForTurn = nil
        print("âœ… ConversationController: ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’è¨­å®š - Parent=\(userId), Child=\(childId), Name=\(childCallName ?? "n/a")")
    }

    private static func pcmFromWavIfPossible(_ data: Data) -> Data? {
        // RIFF/WAVEãƒ˜ãƒƒãƒ€ãƒã‚§ãƒƒã‚¯
        guard data.count >= 12,
              String(data: data[0..<4], encoding: .ascii) == "RIFF",
              String(data: data[8..<12], encoding: .ascii) == "WAVE" else {
            return nil
        }

        var offset = 12 // RIFFãƒ˜ãƒƒãƒ€ã®å¾Œã‹ã‚‰ãƒãƒ£ãƒ³ã‚¯ã‚’èµ°æŸ»
        var fmtFound = false
        var audioFormat: UInt16 = 0
        var bitsPerSample: UInt16 = 0

        while offset + 8 <= data.count {
            let chunkIDData = data[offset..<offset+4]
            let chunkSize = data[offset+4..<offset+8].withUnsafeBytes { $0.load(as: UInt32.self) }
            let chunkID = String(data: chunkIDData, encoding: .ascii) ?? ""
            let chunkStart = offset + 8
            let chunkEnd = chunkStart + Int(chunkSize)
            guard chunkEnd <= data.count else { return nil }

            if chunkID == "fmt " {
                // PCM16ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç¢ºèª
                guard chunkSize >= 16 else { return nil }
                audioFormat = data[chunkStart..<chunkStart+2].withUnsafeBytes { $0.load(as: UInt16.self) }
                bitsPerSample = data[chunkStart+14..<chunkStart+16].withUnsafeBytes { $0.load(as: UInt16.self) }
                fmtFound = true
            } else if chunkID == "data" {
                guard fmtFound, audioFormat == 1, bitsPerSample == 16 else { return nil }
                let pcmRange = chunkStart..<chunkEnd
                return data.subdata(in: pcmRange)
            }

            // ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã¯å¶æ•°å¢ƒç•Œã«æƒã†ãŸã‚ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°è€ƒæ…®
            offset = chunkEnd + (chunkSize % 2 == 1 ? 1 : 0)
        }
        return nil
    }

    /// Firebaseã‚¨ãƒ©ãƒ¼ã®è©³ç´°ãƒ­ã‚°å‡ºåŠ›ï¼ˆPermission deniedã®å ´åˆã«ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ«ãƒ¼ãƒ«ã®è¨­å®šæ–¹æ³•ã‚’æ¡ˆå†…ï¼‰
    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‘¼ã¶ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰ã«ã—ã¦ã„ã‚‹
    func logFirebaseError(_ error: Error, operation: String) {
        let errorString = String(describing: error)
        print("âŒ ConversationController: \(operation)å¤±æ•— - \(errorString)")

        // Permission deniedã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ«ãƒ¼ãƒ«ã®è¨­å®šæ–¹æ³•ã‚’æ¡ˆå†…
        if errorString.contains("Permission denied") || errorString.contains("Missing or insufficient permissions") {
            print("""
            âš ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ«ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚
            é–‹ç™ºç’°å¢ƒã§ã¯ã€Firebaseã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã‚’è¨­å®šã—ã¦ãã ã•ã„:

            rules_version = '2';
            service cloud.firestore {
              match /databases/{database}/documents {
                match /{document=**} {
                  allow read, write: if true;
                }
              }
            }

            è©³ç´°ã¯ FIREBASE_SUMMARY.md ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
            """)
        }
    }

    // MARK: - Lifecycle
    public init(
        audioSession: AudioSessionManaging = SystemAudioSessionManager(),
        speech: SpeechRecognizing = SystemSpeechRecognizer(locale: "ja-JP"),
        handsFreeSpeech: SpeechRecognizing = SystemSpeechRecognizer(locale: "ja-JP")
    ) {
        self.audioSession = audioSession
        self.speech = speech
        self.handsFreeSpeech = handsFreeSpeech
        // âœ… å…±é€šã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨ã—ã¦PlayerNodeStreamerã‚’åˆæœŸåŒ–ï¼ˆAECæœ‰åŠ¹åŒ–ã®ãŸã‚ï¼‰
        self.player = PlayerNodeStreamer(sharedEngine: sharedAudioEngine)
        // âœ… HFPæ™‚ã®äºŒé‡å†ç”Ÿå¯¾ç­–ï¼šæ¯å›PlayerNodeã‚’ä½œã‚Šç›´ã—ã¦ãƒãƒƒãƒ•ã‚¡æ®‹ç•™ã‚’é˜²ã
        self.player.setHardResetPlayerOnPrepare(true)
        super.init()
        setupAppLifecycleObservers()
    }

    deinit {
        // âœ… deinitã¯åŒæœŸçš„ã«å®Ÿè¡Œã•ã‚Œã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€éåŒæœŸå‡¦ç†ã¯è¡Œã‚ãªã„
        // åŒæœŸçš„ã«å®Ÿè¡Œå¯èƒ½ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®ã¿ã‚’è¡Œã†

        // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        sessionStartTask?.cancel()
        sessionStartTask = nil
        if let observer = routeChangeObserver {
            NotificationCenter.default.removeObserver(observer)
            routeChangeObserver = nil
        }
        liveSummaryTask?.cancel()
        liveSummaryTask = nil

        // å—ä¿¡ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        receiveTextTask?.cancel()
        receiveTextTask = nil
        receiveAudioTask?.cancel()
        receiveAudioTask = nil
        receiveInputTextTask?.cancel()
        receiveInputTextTask = nil

        // ãƒã‚¤ã‚¯ã¨ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’åœæ­¢ï¼ˆdeinitã¯éisolatedãªã®ã§ç›´æ¥åœæ­¢ï¼‰
        mic?.stop()
        mic = nil
        player.stop()

        // å…±é€šã‚¨ãƒ³ã‚¸ãƒ³ã‚’åœæ­¢
        if sharedAudioEngine.isRunning {
            sharedAudioEngine.stop()
        }

        // ä¿ƒã—ã‚¿ã‚¤ãƒãƒ¼ã‚’åœæ­¢ï¼ˆdeinitå†…ã§ã¯ç›´æ¥ç„¡åŠ¹åŒ–ï¼‰
        // âœ… cancelNudge()ã¯@MainActorã§åˆ†é›¢ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€deinitå†…ã§ã¯ç›´æ¥ã‚¿ã‚¤ãƒãƒ¼ã‚’ç„¡åŠ¹åŒ–
        nudgeTimer?.invalidate()
        nudgeTimer = nil

        // Local STTã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        // âœ… removeTapã¯ã‚¿ãƒƒãƒ—ãŒå­˜åœ¨ã—ãªã„å ´åˆã§ã‚‚ã‚¨ãƒ©ãƒ¼ã‚’æŠ•ã’ãªã„ãŸã‚ã€å®‰å…¨ã«å‘¼ã³å‡ºã›ã‚‹
        audioEngine.inputNode.removeTap(onBus: 0)
        if audioEngine.isRunning {
            audioEngine.stop()
        }
        sttRequest?.endAudio()
        sttTask?.cancel()
        sttRequest = nil
        sttTask = nil

        // realtimeClientã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆéåŒæœŸå‡¦ç†ã¯å®Ÿè¡Œã—ãªã„ï¼‰
        // finishSession()ã¯éåŒæœŸå‡¦ç†ã®ãŸã‚ã€deinitå†…ã§ã¯å®Ÿè¡Œã—ãªã„
        // ä»£ã‚ã‚Šã«ã€realtimeClientã®å‚ç…§ã‚’nilã«ã—ã¦ã€deinitæ™‚ã«è‡ªå‹•çš„ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
        realtimeClient = nil
        if let observer = routeChangeObserver {
            NotificationCenter.default.removeObserver(observer)
            routeChangeObserver = nil
        }
        
        lifecycleObserverTokens.forEach { NotificationCenter.default.removeObserver($0) }
        lifecycleObserverTokens.removeAll()
        #if canImport(UIKit)
        if backgroundTaskId != .invalid {
            UIApplication.shared.endBackgroundTask(backgroundTaskId)
            backgroundTaskId = .invalid
        }
        #endif

        print("âœ… ConversationController: deinit - ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
    }

    // MARK: - Permissions
    public func requestPermissions() {
        AVAudioSession.sharedInstance().requestRecordPermission { [weak self] granted in
            DispatchQueue.main.async {
                self?.hasMicrophonePermission = granted
            }
        }
        SFSpeechRecognizer.requestAuthorization { _ in }
    }

    // MARK: - Local STT (DIå¯¾å¿œç‰ˆ)
    public func startLocalTranscription() {
        guard !isRecording else { return }
        guard speech.isAvailable else {
            self.errorMessage = "éŸ³å£°èªè­˜ãŒç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
            return
        }
        if isHandsFreeMode {
            stopHandsFreeConversation()
        }

        // 1) AudioSession ã‚’å…ˆã«æ§‹æˆï¼ˆDIçµŒç”±ï¼‰
        do { try audioSession.configure() } catch {
            self.errorMessage = "AudioSessioné–‹å§‹ã«å¤±æ•—: \(error.localizedDescription)"
            return
        }

        // 2) ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
        let req = SFSpeechAudioBufferRecognitionRequest()
        req.shouldReportPartialResults = true
        self.sttRequest = req
        self.transcript = ""
        self.errorMessage = nil

        // 3) ãƒã‚¤ã‚¯ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¸æµã™ï¼ˆformat: nil ã§è£…ç½®ã®æ­£ã—ã„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«è¿½éšï¼‰
        let input = audioEngine.inputNode
        input.removeTap(onBus: 0)
        input.installTap(onBus: 0, bufferSize: 1024, format: nil) { [weak self] buffer, _ in
            self?.sttRequest?.append(buffer)
        }

        // 4) ã‚¨ãƒ³ã‚¸ãƒ³èµ·å‹•
        do {
            audioEngine.prepare()
            try audioEngine.start()
        } catch {
            self.errorMessage = "AudioEngineé–‹å§‹ã«å¤±æ•—: \(error.localizedDescription)"
            input.removeTap(onBus: 0)
            self.sttRequest = nil
            return
        }

        // 5) èªè­˜ï¼ˆãƒ—ãƒ­ãƒˆã‚³ãƒ«çµŒç”±ï¼‰
        sttTask = speech.startTask(
            request: req,
            onResult: { [weak self] text, isFinal in
                Task { @MainActor in
                    self?.transcript = text
                    if isFinal { self?.stopLocalTranscription() }
                }
            },
            onError: { [weak self] err in
                guard let self else { return }

                // ã‚­ãƒ£ãƒ³ã‚»ãƒ«/ç„¡éŸ³ãªã©ã®"æ­£å¸¸çµ‚äº†æ‰±ã„"ã¯ UI ã«å‡ºã•ãªã„
                if self.userStoppedRecording || Self.isBenignSpeechError(err) {
                    Task { @MainActor in self.finishSTTCleanup() }
                    return
                }

                // ãã‚Œä»¥å¤–ã®ã¿ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
                Task { @MainActor in
                    self.errorMessage = err.localizedDescription
                    self.finishSTTCleanup()
                }
            }
        )

        isRecording = true
        mode = .localSTT
    }

    public func stopLocalTranscription() {
        guard isRecording || sttTask != nil else { return }
        userStoppedRecording = true                // ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã¦ã‹ã‚‰
        audioEngine.inputNode.removeTap(onBus: 0)
        audioEngine.stop()
        sttRequest?.endAudio()
        sttTask?.cancel()                          // ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã¯å¿…è¦ã€‚ä¸Šã§ç„¡å®³æ‰±ã„ã«ã™ã‚‹
        finishSTTCleanup()
    }

    // NOTE: Realtime session lifecycle was moved to:
    // - ConversationController/ConversationController+RealtimeSession.swift

    // NOTE: PTT was moved to:
    // - ConversationController/ConversationController+PTT.swift

    // NOTE: HandsFree VAD was moved to:
    // - ConversationController/ConversationController+HandsFreeVAD.swift
    //
    // NOTE: Audio-preview request senders + helpers were moved to:
    // - ConversationController/ConversationController+AudioPreviewRequests.swift
    // NOTE: fallbackTTSInput was moved to:
    // - ConversationController/ConversationController+Prompts.swift

    // NOTE: fallback TTS was moved to:
    // - ConversationController/ConversationController+FallbackTTS.swift

    // NOTE: Diagnostics helpers were moved to:
    // - ConversationController/ConversationController+Diagnostics.swift

    private func finishSTTCleanup() {
        sttRequest = nil
        sttTask = nil
        isRecording = false
        let finalText = transcript.trimmingCharacters(in: .whitespacesAndNewlines)
        let userStopped = userStoppedRecording
        userStoppedRecording = false

        // ãƒ¦ãƒ¼ã‚¶ãƒ¼åœæ­¢ or æœ€çµ‚ç¢ºå®šå¾Œã«ã€æœ¬æ–‡ãŒã‚ã‚Œã°AIã¸
        if !finalText.isEmpty, userStopped || !finalText.isEmpty {
            askAI(with: finalText)
        }
    }

    static func isBenignSpeechError(_ error: Error) -> Bool {
        let e = error as NSError
        let msg = e.localizedDescription.lowercased()
        // iOSã®ãƒ­ãƒ¼ã‚«ãƒ«éŸ³å£°èªè­˜ã§é »ç™ºã™ã‚‹ã‚¨ãƒ©ãƒ¼ã¯â€œç›£è¦–ç”¨é€”â€ã§ã¯ç„¡å®³æ‰±ã„ã«ã—ã¦å†èµ·å‹•ã™ã‚‹
        if e.domain == "kAFAssistantErrorDomain" && (e.code == 1101 || e.code == 1110) {
            return true
        }
        // Speech.frameworkå´ï¼ˆç«¯æœ«/OSã§æºã‚Œã‚‹ï¼‰ã‚‚ã€Œç›£è¦–ç”¨é€”ã€ã§ã¯ç„¡å®³æ‰±ã„
        if e.domain == "kLSRErrorDomain" && (e.code == 301 || e.code == 203 || e.code == 216) {
            return true
        }
        // "canceled""no speech detected" ãªã©ã¯ç„¡å®³æ‰±ã„
        return msg.contains("canceled") || msg.contains("no speech")
        // å¿…è¦ãªã‚‰ã‚³ãƒ¼ãƒ‰ã§åˆ†å²ï¼ˆç’°å¢ƒã§ç•°ãªã‚‹ãŒ 203/216 ã‚’è¦‹ã‚‹ã“ã¨ãŒå¤šã„ï¼‰
        // || e.code == 203 || e.code == 216
    }

    // MARK: - AIå‘¼ã³å‡ºã—
    public func askAI(with userText: String) {
        // åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã‚’é€£æŠ•ã—ãªã„
        guard userText != lastAskedText else { return }
        lastAskedText = userText

        print("ğŸŸ¥ aiResponseText cleared at:", #function)
        aiResponseText = ""              // æ–°ã—ã„ã‚¿ãƒ¼ãƒ³ã®é–‹å§‹
        isThinking = true
        errorMessage = nil

        Task {
            defer {
                Task { @MainActor in
                    self.isThinking = false
                }
            }

            // OpenAI Chat Completions
            struct Payload: Encodable {
                let model: String
                let messages: [[String: String]]
                let max_tokens: Int?
                let temperature: Double?
            }

            let nameNote: String
            if let callName = childCallName {
                nameNote = "ã“ã©ã‚‚ã®ãªã¾ãˆã¯ã€Œ\(callName)ã€ã€‚ã‚ã„ã•ã¤ã‚„ã“ãŸãˆã®ä¸­ã§ã€ã‚ˆã†ã™ã«ã‚ã‚ã›ã¦ã‚„ã•ã—ãåå‰ã‚’å…¥ã‚Œã¦ã­ï¼ˆã‚Œã‚“ã“ã¯ç¦æ­¢ï¼‰ã€‚"
            } else {
                nameNote = ""
            }

            let payload = Payload(
                model: "gpt-4o-mini",
                messages: [
                    ["role": "system", "content": "ã‚ãªãŸã¯å¹¼å…å‘ã‘ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã®ã¿ã§ç­”ãˆã¦ãã ã•ã„ã€‚ã²ã‚‰ãŒãªä¸­å¿ƒãƒ»ä¸€æ–‡ã‚’çŸ­ããƒ»ã‚„ã•ã—ããƒ»ã‚€ãšã‹ã—ã„è¨€è‘‰ã‚’ã•ã‘ã¾ã™ã€‚" + (nameNote.isEmpty ? "" : " " + nameNote)],
                    ["role": "user", "content": userText]
                ],
                max_tokens: 120,
                temperature: 0.3
            )

            let endpoint = (Bundle.main.object(forInfoDictionaryKey: "API_BASE") as? String)
                .flatMap(URL.init(string:)) ?? URL(string: "https://api.openai.com/v1")!

            var req = URLRequest(url: endpoint.appendingPathComponent("chat/completions"))
            req.httpMethod = "POST"
            req.addValue("application/json", forHTTPHeaderField: "Content-Type")
            req.addValue("Bearer \(AppConfig.openAIKey)", forHTTPHeaderField: "Authorization")
            req.httpBody = try? JSONEncoder().encode(payload)

            // 429 ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆæœ€å¤§3å›ã€0.5sâ†’1sâ†’2sï¼‰
            var attempt = 0
            let maxAttempts = 3
            var backoff: UInt64 = 500_000_000 // 0.5s

            while attempt < maxAttempts {
                do {
                    let (data, response) = try await URLSession.shared.data(for: req)
                    guard let http = response as? HTTPURLResponse else {
                        throw URLError(.badServerResponse)
                    }

                    if http.statusCode == 429 {
                        // ã‚¨ãƒ©ãƒ¼ãƒœãƒ‡ã‚£ã‚’è§£æã—ã¦æ–‡è¨€åŒ–
                        let msg = Self.readable429Message(from: data)
                        attempt += 1
                        if attempt >= maxAttempts {
                            await MainActor.run {
                                self.errorMessage = msg
                                self.isThinking = false
                            }
                            return
                        }
                        try await Task.sleep(nanoseconds: backoff)
                        backoff *= 2
                        continue
                    }

                    guard (200..<300).contains(http.statusCode) else {
                        // 429 ä»¥å¤–ã®ã‚¨ãƒ©ãƒ¼
                        let body = String(data: data, encoding: .utf8) ?? ""
                        throw NSError(domain: "OpenAI", code: http.statusCode,
                                      userInfo: [NSLocalizedDescriptionKey: "HTTP \(http.statusCode): \(body)"])
                    }

                    struct Choice: Decodable {
                        struct Message: Decodable { let role: String; let content: String }
                        let message: Message
                    }
                    struct Resp: Decodable { let choices: [Choice] }
                    let decoded = try JSONDecoder().decode(Resp.self, from: data)
                    let text = decoded.choices.first?.message.content ?? "(ãŠã¸ã‚“ã˜ãŒã§ããªã‹ã£ãŸã‚ˆ)"

                    await MainActor.run {
                        self.aiResponseText = text
                        self.isThinking = false
                    }
                    return
                } catch {
                    // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾‹å¤–ãªã©
                    await MainActor.run {
                        self.errorMessage = Self.humanReadable(error)
                        self.isThinking = false
                    }
                    return
                }
            }
        }
    }

    private static func readable429Message(from data: Data) -> String {
        // OpenAI ã‚¨ãƒ©ãƒ¼å½¢å¼ã«å¯¾å¿œ
        struct OpenAIError: Decodable {
            struct Inner: Decodable {
                let message: String
                let type: String?
                let code: String?
            }
            let error: Inner
        }
        if let e = try? JSONDecoder().decode(OpenAIError.self, from: data) {
            if let code = e.error.code?.lowercased(), code.contains("insufficient_quota") {
                return "ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆæ®‹é«˜ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆinsufficient_quotaï¼‰ã€‚è«‹æ±‚/ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            }
            if let code = e.error.code?.lowercased(), code.contains("rate_limit") {
                return "ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤šã™ãã¾ã™ï¼ˆrate limitï¼‰ã€‚å°‘ã—å¾…ã£ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŸã‚ã—ã¦ã­ã€‚"
            }
            return e.error.message
        }
        return "429: ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŸã‚ã—ã¦ã­ã€‚"
    }

private static func humanReadable(_ error: Error) -> String {
    if let u = error as? URLError {
        switch u.code {
        case .cannotFindHost: return "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ï¼šãƒ›ã‚¹ãƒˆåãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆAPI_BASEã‚’ç¢ºèªï¼‰"
            case .notConnectedToInternet: return "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã«æ¥ç¶šã§ãã¾ã›ã‚“"
            case .userAuthenticationRequired, .userCancelledAuthentication: return "APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ï¼ˆ401ï¼‰"
            default: break
            }
        }
        return error.localizedDescription
    }

    /// æ—¥æœ¬èªä»¥å¤–ã‚„ä½™è¨ˆãªãƒ•ãƒƒã‚¿ã‚’å–ã‚Šé™¤ãè»½ã„ã‚µãƒ‹ã‚¿ã‚¤ã‚º
    // NOTE: prompt/sanitize helpers were moved to:
    // - ConversationController/ConversationController+Prompts.swift

    // NOTE: Live analysis was moved to:
    // - ConversationController/ConversationController+Analysis.swift

    // MARK: - ä¿ƒã—ã‚¿ã‚¤ãƒãƒ¼æ©Ÿèƒ½

    // âœ… ä¿®æ­£: ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆ10.0ç§’ã«å»¶é•·ã€ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°å¼·åŒ–ï¼‰
    func startWaitingForResponse() {
        print("â¹ ConversationController: ä¿ƒã—æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ä¸­ï¼ˆã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚»ãƒƒãƒˆã—ã¾ã›ã‚“ï¼‰")
        cancelNudge()
    }

    // âœ… ä¿®æ­£: ã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ã«é–¢ã‚ã‚‰ãšã€å®Ÿéš›ã®ç„¡éŸ³æ™‚é–“ãŒé•·ã‘ã‚Œã°ä¿ƒã™
    private func sendNudgeIfNoResponse() async {
        // ä¿ƒã—æ©Ÿèƒ½ã‚’åœæ­¢ä¸­
        print("â¹ ConversationController: ä¿ƒã—æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ä¸­ï¼ˆnudgeé€ä¿¡ã‚‚è¡Œã„ã¾ã›ã‚“ï¼‰")
        cancelNudge()
        return

        guard isRealtimeActive else {
            print("âš ï¸ ConversationController: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã§ãªã„ãŸã‚ nudge ã‚¹ã‚­ãƒƒãƒ—")
            return
        }

        // æœ€å¾Œã«éŸ³ãŒã—ã¦ã‹ã‚‰ä½•ç§’çµŒéã—ãŸã‹
        let silenceDuration = Date().timeIntervalSince(lastUserVoiceActivityTime)
        print("ğŸ§ ConversationController: Nudgeåˆ¤å®š - State: \(turnState), å®Ÿéš›ã®ç„¡éŸ³çµŒéæ™‚é–“: \(String(format: "%.1f", silenceDuration))ç§’")

        // ---------------------------------------------------------
        // åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯:
        // 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—ã¦ã„ã‚‹(.listening)ã“ã¨ã«ãªã£ã¦ã„ã‚‹ãŒã€
        // 2. å®Ÿã¯ã“ã“4ç§’ä»¥ä¸Šã€ãƒã‚¤ã‚¯å…¥åŠ›ãŒé™ã‹(-50dBä»¥ä¸‹)ã§ã‚ã‚‹å ´åˆ
        //    â†’ ã€ŒVADã®èª¤æ¤œçŸ¥ï¼ˆã¾ãŸã¯å¼µã‚Šä»˜ãï¼‰ã€ã¨ã¿ãªã—ã¦ã€å¼·åˆ¶çš„ã«ä¿ƒã—ã‚’å®Ÿè¡Œã™ã‚‹
        // ---------------------------------------------------------

        let isActuallySilent = silenceDuration > 4.0 // å°‘ã—ä½™è£•ã‚’è¦‹ã¦4.0ç§’ä»¥ä¸Šé™ã‹ãªã‚‰ç„¡éŸ³ã¨ã™ã‚‹

        if case .listening = turnState {
            if isActuallySilent {
                print("ğŸš€ ConversationController: Stateã¯listeningã§ã™ãŒã€å®Ÿéš›ã«ã¯ç„¡éŸ³(\(String(format: "%.1f", silenceDuration))s)ã®ãŸã‚ã€ä¿ƒã—ã‚’å¼·åˆ¶å®Ÿè¡Œã—ã¾ã™")
                // ãã®ã¾ã¾ä¸‹ã¸æµã—ã¦å®Ÿè¡Œã•ã›ã‚‹
            } else {
                print("âš ï¸ ConversationController: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå®Ÿéš›ã«è©±ã—ã¦ã„ã‚‹(éŸ³é‡å¤§)ãŸã‚ nudge ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                cancelNudge()
                return
            }
        }

        // ä»–ã®çŠ¶æ…‹ï¼ˆAIãŒè€ƒãˆã¦ã„ã‚‹ã€è©±ã—ã¦ã„ã‚‹ï¼‰ã®å ´åˆã¯å¾“æ¥ã©ãŠã‚Šã‚¹ã‚­ãƒƒãƒ—
        if case .thinking = turnState {
            print("âš ï¸ ConversationController: å¿œç­”ç”Ÿæˆä¸­(thinking)ã®ãŸã‚ nudge ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            cancelNudge()
            return
        }
        if case .speaking = turnState {
            print("âš ï¸ ConversationController: AIãŒè©±ã—ã¦ã„ã‚‹(speaking)ã®ãŸã‚ nudge ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            cancelNudge()
            return
        }

        // ã“ã“ã¾ã§æ¥ãŸã‚‰é€ä¿¡
        guard nudgeCount < maxNudgeCount else {
            print("â¹ ConversationController: ä¿ƒã—é€ä¿¡ã‚’\(maxNudgeCount)å›ã§åœæ­¢ã—ã¾ã™")
            cancelNudge()
            return
        }
        print("ğŸš€ ConversationController: æ¡ä»¶ã‚¯ãƒªã‚¢ -> ä¿ƒã—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡å®Ÿè¡Œ")
        print("â„¹ï¸ ConversationController: Realtime APIç„¡åŠ¹åŒ–ä¸­ã®ãŸã‚ nudge ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆgpt-4o-audio-previewã«åˆã‚ã›ã¦å¾Œç¶šã§å®Ÿè£…æ¤œè¨ï¼‰")
        nudgeCount += 1
    }

    // NOTE: åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®extensionã‹ã‚‰å‘¼ã¶ãŸã‚ internalï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…é™å®šï¼‰
    func cancelNudge() {
        nudgeTimer?.invalidate()
        nudgeTimer = nil
    }

    // âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã«æœ€åˆã®è³ªå•ã‚’ç”Ÿæˆã™ã‚‹
    public func requestInitialGreeting() {
        guard isRealtimeActive else {
            print("âš ï¸ ConversationController: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã§ãªã„ãŸã‚ initial greeting ã‚¹ã‚­ãƒƒãƒ—")
            return
        }

        Task {
            print("ğŸš€ ConversationController: æœ€åˆã®è³ªå•ã‚’ç”Ÿæˆä¸­...")
            print("â„¹ï¸ ConversationController: Realtime APIç„¡åŠ¹åŒ–ä¸­ã®ãŸã‚ nudge ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆgpt-4o-audio-previewã«åˆã‚ã›ã¦å¾Œç¶šã§å®Ÿè£…æ¤œè¨ï¼‰")
        }
    }

    // NOTE: Session analysis was moved to:
    // - ConversationController/ConversationController+Analysis.swift
}

// NOTE: AudioPreviewStreamingClient + payload models were moved to:
// - ConversationController/AudioPreviewStreamingClient.swift
