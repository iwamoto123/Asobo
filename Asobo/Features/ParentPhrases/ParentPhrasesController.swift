import Foundation
import SwiftUI
import AVFoundation
import Domain
import DataStores
import Services
import Support
import Speech

private let analytics = AnalyticsService.shared

@available(iOS 17.0, *)
@MainActor
public final class ParentPhrasesController: ObservableObject {
    @Published var cards: [PhraseCard] = []
    @Published var hasLoadedCards: Bool = false
    @Published var customCategories: [PhraseCategory] = []
    @Published var isRecording: Bool = false
    @Published var isVoiceInputPresented: Bool = false
    @Published var voiceInputText: String = ""
    @Published var voiceInputError: String?
    @Published var voiceInputRMS: Double = -60.0
    @Published var isPlaying: Bool = false
    @Published var preparingCardId: UUID?
    @Published var editCard: PhraseCard?
    @Published var playingCardId: UUID?  // å†ç”Ÿä¸­ã®ã‚«ãƒ¼ãƒ‰ID
    @Published var playbackProgress: Double = 0.0  // å†ç”Ÿé€²æ— (0.0ã€œ1.0)

    private let repository: ParentPhrasesRepository
    private let customCategoriesKey: String
    private let removedCategoriesMigrationKey: String
    // extensionï¼ˆåˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‹ã‚‰éŸ³å£°å…¥åŠ›ã‚¿ãƒƒãƒ—ã«ä½¿ã†ãŸã‚ internal ã«ã—ã¦ã„ã‚‹
    // âœ… å†ç”Ÿç³»ï¼ˆTTS/PlayerNodeStreamerï¼‰å°‚ç”¨
    let audioEngine: AVAudioEngine
    // âœ… éŸ³å£°å…¥åŠ›ï¼ˆSTTï¼‰å°‚ç”¨ï¼šå†ç”Ÿç³»ã¨åˆ†é›¢ã—ã¦ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ã¸ã®å½±éŸ¿ã‚’ã‚¼ãƒ­ã«å¯„ã›ã‚‹
    private let sttEngine: AVAudioEngine
    private let player: PlayerNodeStreamer
    private let ttsEngine: TTSEngineProtocol  // âœ… ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§å®£è¨€ï¼ˆåˆ‡ã‚Šæ›¿ãˆå¯èƒ½ï¼‰
    private var playQueueTask: Task<Void, Never>?
    private var currentPlayRequestId: String?
    private let speech: SpeechRecognizing
    var speechTask: SpeechRecognitionTasking?
    var speechRequest: SFSpeechAudioBufferRecognitionRequest?
    // extensionï¼ˆåˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‹ã‚‰åœæ­¢å‡¦ç†ã«ä½¿ã†ãŸã‚ internal ã«ã—ã¦ã„ã‚‹
    var micCapture: MicrophoneCapture?
    // extensionï¼ˆåˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‹ã‚‰åœæ­¢å‡¦ç†ã«ä½¿ã†ãŸã‚ internal ã«ã—ã¦ã„ã‚‹
    var micBufferObserver: NSObjectProtocol?
    var micRMSObserver: NSObjectProtocol?
    var voiceInputFallbackTask: Task<Void, Never>?
    var voiceInputLastBufferAt: Date?
    private var voiceInputPrefixText: String = ""

    public init(userId: String?) {
        // ãƒªãƒã‚¸ãƒˆãƒªã®é¸æŠ
        if let userId = userId {
            // Firebaseä¿å­˜ï¼ˆæœ¬ç•ªç”¨ï¼‰
            self.repository = FirebaseParentPhrasesRepository(userId: userId)
            print("ğŸ”¥ ParentPhrasesController: Firebaseãƒªãƒã‚¸ãƒˆãƒªã‚’ä½¿ç”¨ - userId=\(userId)")
        } else {
            // ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ï¼ˆSwiftDataï¼‰- ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self.repository = try! SwiftDataParentPhrasesRepository()
            print("ğŸ’¾ ParentPhrasesController: SwiftDataãƒªãƒã‚¸ãƒˆãƒªã‚’ä½¿ç”¨ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰")
        }

        // AudioEngine ã¨ PlayerNodeStreamer ã®åˆæœŸåŒ–
        self.audioEngine = AVAudioEngine()
        self.sttEngine = AVAudioEngine()
        self.player = PlayerNodeStreamer(sharedEngine: audioEngine)
        self.speech = SystemSpeechRecognizer(locale: "ja-JP")
        self.customCategoriesKey = "ParentPhrases.customCategories.\(userId ?? "local")"
        self.removedCategoriesMigrationKey = "ParentPhrases.migration.removedOutingReturnHome.\(userId ?? "local")"

        // TTS ã‚¨ãƒ³ã‚¸ãƒ³ã®é¸æŠï¼ˆã©ã¡ã‚‰ã‹ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
        // 1. OpenAI TTSï¼ˆé«˜å“è³ªã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¿…é ˆã€æœ‰æ–™ï¼‰
        self.ttsEngine = TTSEngine(player: player)

        // 2. AVSpeechSynthesizerï¼ˆiOSæ¨™æº–ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã€ç„¡æ–™ã€ãƒã‚¹ã‚³ãƒƒãƒˆçš„ãªå£°ï¼‰
        // self.ttsEngine = AVSpeechTTSEngine()

        Task {
            self.loadCustomCategories()
            await loadCards()
        }
    }

    func availableCategories() -> [PhraseCategory] {
        var list: [PhraseCategory] = []
        let other = PhraseCategory.other

        // 1) å†…è”µã‚«ãƒ†ã‚´ãƒªï¼ˆã€Œãã®ä»–ã€ã¯æœ€å¾Œã«å›ã™ï¼‰
        for c in PhraseCategory.builtinAllCases where !c.name.isEmpty && c != other {
            if !list.contains(c) { list.append(c) }
        }

        // 2) ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ ã‚«ãƒ†ã‚´ãƒªï¼ˆå¸¸ã«ã€Œãã®ä»–ã€ã‚ˆã‚Šå‰ï¼‰
        for c in customCategories where !c.name.isEmpty && c != other {
            if !list.contains(c) { list.append(c) }
        }

        // 3) æ—¢å­˜ã‚«ãƒ¼ãƒ‰ã‹ã‚‰æ¤œå‡ºã•ã‚ŒãŸæœªç™»éŒ²ã‚«ãƒ†ã‚´ãƒªï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚«ãƒ†ã‚´ãƒªæ‰±ã„ã§ã€Œãã®ä»–ã€ã‚ˆã‚Šå‰ï¼‰
        for card in cards {
            let c = card.category
            if !c.name.isEmpty && c != other && !PhraseCategory.builtinAllCases.contains(c) {
                if !list.contains(c) { list.append(c) }
            }
        }

        // 4) ã€Œãã®ä»–ã€ã¯å¸¸ã«æœ€å¾Œ
        if !list.contains(other) { list.append(other) }
        return list
    }

    func addCustomCategory(_ name: String) {
        let c = PhraseCategory(name)
        guard !c.name.isEmpty else { return }
        if !customCategories.contains(c) {
            customCategories.append(c)
            persistCustomCategories()
            analytics.log(.categoryCreated(name: name))
        }
    }

    private func loadCustomCategories() {
        let arr = UserDefaults.standard.array(forKey: customCategoriesKey) as? [String] ?? []
        self.customCategories = arr.map { PhraseCategory($0) }.filter { !$0.name.isEmpty }
    }

    private func persistCustomCategories() {
        let arr = customCategories.map(\.name)
        UserDefaults.standard.set(arr, forKey: customCategoriesKey)
    }

    private func ensureVoiceInputPermissions() async -> Bool {
        let micOK: Bool = await withCheckedContinuation { cont in
            AVAudioSession.sharedInstance().requestRecordPermission { granted in
                cont.resume(returning: granted)
            }
        }
        if !micOK {
            voiceInputError = "ãƒã‚¤ã‚¯ã®è¨±å¯ãŒå¿…è¦ã§ã™ï¼ˆè¨­å®š > Asobo > ãƒã‚¤ã‚¯ï¼‰"
            return false
        }

        let speechOK: Bool = await withCheckedContinuation { cont in
            SFSpeechRecognizer.requestAuthorization { status in
                cont.resume(returning: status == .authorized)
            }
        }
        if !speechOK {
            voiceInputError = "éŸ³å£°èªè­˜ã®è¨±å¯ãŒå¿…è¦ã§ã™ï¼ˆè¨­å®š > Asobo > éŸ³å£°èªè­˜ï¼‰"
            return false
        }
        return true
    }

    private func ensureAudioEngineRunning(reason: String) -> Bool {
        do {
            audioEngine.prepare()
            if !audioEngine.isRunning {
                try audioEngine.start()
                print("âœ… ParentPhrasesController: AudioEngine started (\(reason))")
            }
            return true
        } catch {
            print("âŒ ParentPhrasesController: AudioEngine start failed (\(reason)) - \(error.localizedDescription)")
            return false
        }
    }

    /// âœ… éBluetoothæ™‚ã« Receiverï¼ˆå—è©±å£ï¼‰ã¸è½ã¡ãŸå ´åˆã ã‘ã€ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã¸æˆ»ã™
    /// - Note: å£°ã‹ã‘å†ç”Ÿã§ .playback ã¸åˆ‡ã‚Šæ›¿ãˆã‚‹ã¨ã€Œãƒ¡ãƒ‡ã‚£ã‚¢éŸ³é‡(0ã«ãªã‚ŠãŒã¡)ã€ã¸åˆ‡ã‚Šæ›¿ã‚ã‚Šç„¡éŸ³ã«ãªã‚Šå¾—ã‚‹ãŸã‚ã€
    ///         ã‚«ãƒ†ã‚´ãƒª/ãƒ¢ãƒ¼ãƒ‰ã¯è§¦ã‚‰ãšã€ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã ã‘ã‚’æœ€ä½é™è£œå¼·ã™ã‚‹ã€‚
    private func ensureSpeakerOutputIfNoBluetooth(reason: String) {
        let s = AVAudioSession.sharedInstance()
        let hasBluetoothOutput = s.currentRoute.outputs.contains(where: { out in
            out.portType == .bluetoothHFP || out.portType == .bluetoothA2DP || out.portType == .bluetoothLE
        })
        guard !hasBluetoothOutput else { return }

        // âœ… AudioSessionã‚’å¸¸ã«å†è¨­å®šã™ã‚‹ï¼ˆBluetoothåˆ‡æ–­å¾Œã®éŸ³é‡ä½ä¸‹å¯¾ç­–ï¼‰
        // - Bluetooth(HFP)åˆ‡æ–­å¾Œã€ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆãŒ8kHz/16kHzã®ã¾ã¾æ®‹ã‚‹å•é¡Œã‚’è§£æ¶ˆ
        // - .playAndRecord + .defaultToSpeaker ã§ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼å‡ºåŠ›ã‚’ç¢ºä¿
        // - .voiceChat ãƒ¢ãƒ¼ãƒ‰ã§AECæœ‰åŠ¹åŒ–ï¼ˆãƒã‚¤ã‚¯å…¥åŠ›ã¨ã®å¹²æ¸‰ã‚’é˜²ãï¼‰
        // - 48kHz/10msãƒãƒƒãƒ•ã‚¡ã§é«˜å“è³ªå†ç”Ÿã‚’ç¢ºä¿
        do {
            // âœ… AudioEngine ã‚’å¸¸ã«åœæ­¢ï¼ˆBTåˆ‡æ–­å¾Œã®ä¸æ•´åˆçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆï¼‰
            audioEngine.stop()
            // âœ… PlayerNodeStreamer ã®çŠ¶æ…‹ã‚‚ãƒªã‚»ãƒƒãƒˆï¼ˆå†…éƒ¨ãƒãƒƒãƒ•ã‚¡ã‚„æ¥ç¶šã‚’ã‚¯ãƒªã‚¢ï¼‰
            player.prepareForNextStream()
            print("ğŸ”§ ParentPhrasesController: AudioEngine & Player reset (\(reason))")

            try s.setCategory(.playAndRecord, options: [.defaultToSpeaker, .allowBluetooth, .allowBluetoothA2DP])
            try s.setMode(.voiceChat)
            // âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã¨ãƒãƒƒãƒ•ã‚¡ã‚’æ˜ç¤ºçš„ã«è¨­å®šï¼ˆBTåˆ‡æ–­å¾Œã®å¾©æ—§ï¼‰
            try s.setPreferredSampleRate(48_000)
            try s.setPreferredIOBufferDuration(0.01)  // 10ms
            try s.setActive(true)
            print("ğŸ”§ ParentPhrasesController: AudioSession configured - sampleRate=\(s.sampleRate)Hz (\(reason))")
        } catch {
            print("âš ï¸ ParentPhrasesController: AudioSession configuration failed - \(error.localizedDescription)")
        }

        // âœ… éBluetoothæ™‚ã¯å¸¸ã«ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼å‡ºåŠ›ã‚’å¼·åˆ¶ï¼ˆå—è©±å£è½ã¡å¯¾ç­–ï¼‰
        try? s.overrideOutputAudioPort(.speaker)
        #if canImport(UIKit)
        UIDevice.current.isProximityMonitoringEnabled = false
        #endif
        print("ğŸ“¢ ParentPhrasesController: speaker override applied (no BT) (\(reason))")
    }

    private func startStandaloneVoiceCapture() throws {
        // STTå°‚ç”¨ã‚¨ãƒ³ã‚¸ãƒ³ã§ãƒã‚¤ã‚¯ã‚’æ´ã‚€ï¼ˆå†ç”Ÿç³»ã¨ã¯åˆ†é›¢ï¼‰
        micCapture?.stop()
        micCapture = nil

        guard let cap = MicrophoneCapture(
            sharedEngine: sttEngine,
            onPCM: { _ in },
            outputMonitor: nil,
            ownsEngine: true
        ) else {
            throw NSError(domain: "ParentPhrasesController", code: -1, userInfo: [
                NSLocalizedDescriptionKey: "MicrophoneCaptureã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
            ])
        }
        micCapture = cap
        cap.onInputBuffer = { [weak self] buffer in
            guard let self else { return }
            self.voiceInputLastBufferAt = Date()
            self.speechRequest?.append(buffer)
        }
        cap.onVolume = { [weak self] rms in
            guard let self else { return }
            self.voiceInputLastBufferAt = Date()
            Task { @MainActor in
                self.voiceInputRMS = rms
            }
        }
        try cap.start()
    }

    func loadCards() async {
        // åˆå›ãƒ­ãƒ¼ãƒ‰å®Œäº†ã¾ã§ã¯ç©ºçŠ¶æ…‹UIã‚’å‡ºã•ãªã„ï¼ˆãƒãƒ©ã¤ãé˜²æ­¢ï¼‰
        do {
            self.cards = try await repository.fetchAll()
            await migrateRemovedCategoriesIfNeeded()
            print("âœ… ã‚«ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿å®Œäº†: \(cards.count)ä»¶")
        } catch {
            print("âŒ ã‚«ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: \(error)")
        }
        if !hasLoadedCards { hasLoadedCards = true }
    }

    /// ä¸€å›é™ã‚Šã®ç§»è¡Œ: ã€ŒãŠã§ã‹ã‘ã€ã€Œå¸°å®…å¾Œã€ã‚’å‰Šé™¤ã—ãŸã®ã§ã€æ—¢å­˜ã‚«ãƒ¼ãƒ‰/ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ†ã‚´ãƒªãŒã‚ã‚Œã°ã€Œãã®ä»–ã€ã¸å¯„ã›ã‚‹
    private func migrateRemovedCategoriesIfNeeded() async {
        if UserDefaults.standard.bool(forKey: removedCategoriesMigrationKey) { return }

        let removed = Set(["ãŠã§ã‹ã‘", "å¸°å®…å¾Œ"])
        var updated = false

        // ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰é™¤å»
        let filteredCustom = customCategories.filter { !removed.contains($0.name) }
        if filteredCustom.count != customCategories.count {
            customCategories = filteredCustom
            persistCustomCategories()
            updated = true
        }

        // æ—¢å­˜ã‚«ãƒ¼ãƒ‰ã®ã‚«ãƒ†ã‚´ãƒªç§»è¡Œ
        let targets = cards.filter { removed.contains($0.category.name) }
        if !targets.isEmpty {
            for card in targets {
                var c = card
                c.category = .other
                try? await repository.upsert(c)
            }
            updated = true
            self.cards = (try? await repository.fetchAll()) ?? self.cards
        }

        if updated {
            print("ğŸ” ParentPhrasesController: migrated removed categories -> ãã®ä»–")
        }
        UserDefaults.standard.set(true, forKey: removedCategoriesMigrationKey)
    }

    func filteredCards(for category: PhraseCategory) -> [PhraseCard] {
        cards
            .filter { $0.category == category }
            .sorted { card1, card2 in
                // âœ… èµ·å‹•æ™‚ã¯ã€Œä½¿ç”¨å›æ•°ãŒå¤šã„é †ã€
                if card1.usageCount != card2.usageCount { return card1.usageCount > card2.usageCount }
                // ã‚¿ã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¯: æœ€çµ‚ä½¿ç”¨ â†’ å„ªå…ˆé †ä½ â†’ ä½œæˆæ—¥
                if let a = card1.lastUsedAt, let b = card2.lastUsedAt, a != b { return a > b }
                if card1.priority != card2.priority { return card1.priority < card2.priority }
                return card1.createdAt > card2.createdAt
            }
    }

    // ãƒ†ã‚­ã‚¹ãƒˆã‚’ç›´æ¥èª­ã¿ä¸Šã’ï¼ˆä¿å­˜å‰ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ï¼‰
    func playText(_ text: String) {
        let trimmed = text.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !trimmed.isEmpty else { return }

        // å†ç”Ÿä¸­ãªã‚‰æ­¢ã‚ã‚‹
        if isPlaying || playQueueTask != nil || preparingCardId != nil {
            currentPlayRequestId = nil
            playQueueTask?.cancel()
            playQueueTask = nil
            ttsEngine.cancelCurrentPlayback(reason: "user_tapped_preview")
            isPlaying = false
            playingCardId = nil
            preparingCardId = nil
            playbackProgress = 0.0
        }

        let requestId = String(UUID().uuidString.prefix(8))
        playQueueTask = Task { @MainActor [weak self] in
            guard let self else { return }
            self.currentPlayRequestId = requestId
            self.ttsEngine.beginRequest(requestId)
            self.ensureSpeakerOutputIfNoBluetooth(reason: "playText")
            self.audioEngine.mainMixerNode.outputVolume = 1.0
            guard self.ensureAudioEngineRunning(reason: "playText") else { return }

            self.isPlaying = true
            defer {
                if self.currentPlayRequestId == requestId {
                    self.isPlaying = false
                    self.currentPlayRequestId = nil
                }
            }

            do {
                try await self.ttsEngine.speak(text: trimmed, requestId: requestId)
            } catch {
                print("âŒ playText[\(requestId)]: å†ç”Ÿã‚¨ãƒ©ãƒ¼ - text=\"\(trimmed)\", error=\(error.localizedDescription)")
            }
            self.playQueueTask = nil
        }
    }

    // ãƒ•ãƒ¬ãƒ¼ã‚ºèª­ã¿ä¸Šã’
    func playPhrase(_ card: PhraseCard) {
        // âœ… UX: æ–°ã—ã„ã‚«ãƒ¼ãƒ‰ãŒæŠ¼ã•ã‚ŒãŸã‚‰ã€å‰ã®å†ç”Ÿï¼ˆå¾…æ©Ÿä¸­ã®APIå«ã‚€ï¼‰ã‚’å³ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¦å·®ã—æ›¿ãˆã‚‹
        if isPlaying || playQueueTask != nil || preparingCardId != nil {
            currentPlayRequestId = nil
            playQueueTask?.cancel()
            playQueueTask = nil
            ttsEngine.cancelCurrentPlayback(reason: "user_tapped_new_card")
            isPlaying = false
            playingCardId = nil
            preparingCardId = nil
            playbackProgress = 0.0
        }

        analytics.log(.phraseCardPlay(category: card.category.name))

        let requestId = String(UUID().uuidString.prefix(8))
        playQueueTask = Task { @MainActor [weak self] in
            await self?.playCard(card, requestId: requestId)
            self?.playQueueTask = nil
        }
    }

    // å†ç”Ÿæ™‚é–“ã‚’æ¨å®šï¼ˆæ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
    private func estimatePlaybackDuration(text: String) async -> Double {
        // âœ… ä½“æ„Ÿã«åˆã‚ã›ã¦ã€ŒçŸ­ã‚ã€ã«å¯„ã›ã‚‹ï¼ˆé…ã™ãã‚‹å•é¡Œã®æ”¹å–„ï¼‰
        // è¦ªãƒ•ãƒ¬ãƒ¼ã‚ºã¯æ—©å£ãƒ—ãƒªã‚»ãƒƒãƒˆãªã®ã§ã€æ–‡å­—/ç§’ã‚’é«˜ã‚ã«è¨­å®šã™ã‚‹
        // ã¾ã ã€Œå¾ŒåŠã§åŠ é€Ÿã€ã—ã¦è¦‹ãˆã‚‹å ´åˆã¯ã€ã“ã®å€¤ãŒä½ã™ãã¦éŸ³å£°ã‚ˆã‚Šé€²æ—ãŒé…ã„ã®ãŒåŸå› ãªã®ã§ä¸Šã’ã‚‹
        let charsPerSecond = 10.5
        let base = Double(text.count) / charsPerSecond
        // å…ˆé ­/æœ«å°¾ã®ä½™ç™½ + æœ«å°¾ç„¡éŸ³(0.12s)ã‚’åŠ å‘³
        return max(base + 0.20 + 0.12, 0.65)
    }

    private func playCard(_ card: PhraseCard, requestId: String) async {
        currentPlayRequestId = requestId
        ttsEngine.beginRequest(requestId)

        // âœ… éBluetoothæ™‚ã®å—è©±å£è½ã¡å¯¾ç­–ï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ‡æ›¿ã¯ã—ãªã„ï¼‰
        ensureSpeakerOutputIfNoBluetooth(reason: "playCard")
        audioEngine.mainMixerNode.outputVolume = 1.0

        guard ensureAudioEngineRunning(reason: "playCard") else { return }

        // ä½¿ç”¨å›æ•°ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
        try? await repository.incrementUsage(id: card.id)
        await loadCards()

        // TTSã§èª­ã¿ä¸Šã’ï¼ˆé–‹å§‹ã¾ã§ã¯æº–å‚™ä¸­æ‰±ã„ï¼‰
        preparingCardId = card.id
        isPlaying = false
        playingCardId = nil
        playbackProgress = 0.0

        var shouldDelayFinalizeUI = false

        defer {
            if self.currentPlayRequestId == requestId {
                if shouldDelayFinalizeUI {
                    // âœ… 1.0ãŒæç”»ã•ã‚Œã‚‹å‰ã«ãƒãƒ¼ãŒæ¶ˆãˆã‚‹å•é¡Œã‚’é˜²ãï¼ˆä½“æ„Ÿã§ã€Œ99%ã§æ­¢ã¾ã‚‹ã€åŸå› ï¼‰
                    Task { @MainActor [weak self] in
                        guard let self else { return }
                        try? await Task.sleep(nanoseconds: 250_000_000) // 0.25s
                        // âœ… playingCardId ã¯é€”ä¸­ã§å¤‰åŒ–ã—ã†ã‚‹ã®ã§ã€requestIdä¸€è‡´ã ã‘ã§ç¢ºå®Ÿã«è§£æ”¾ã™ã‚‹ï¼ˆå›ºã¾ã‚Šé˜²æ­¢ï¼‰
                        guard self.currentPlayRequestId == requestId else { return }
                        self.isPlaying = false
                        self.playingCardId = nil
                        self.preparingCardId = nil
                        self.playbackProgress = 0.0
                        self.currentPlayRequestId = nil
                    }
                } else {
                self.isPlaying = false
                self.playingCardId = nil
                    self.preparingCardId = nil
                self.playbackProgress = 0.0
                    self.currentPlayRequestId = nil
                }
            }
        }

        do {
            // å†ç”Ÿæ™‚é–“ã‚’æ¨å®šï¼ˆTTSEngineå†…ã®è¨ˆç®—ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
            let estimatedDuration = await estimatePlaybackDuration(text: card.text)

            let speakTask = Task { @MainActor [weak self] in
                try await self?.ttsEngine.speak(text: card.text, requestId: requestId)
            }

            // âœ… å®Ÿå†ç”Ÿé–‹å§‹ã‚’å¾…ã¤ï¼ˆé–‹å§‹å‰ã®APIå¾…ã¡ã§é€²æ—ãŒå‹•ã‹ãªã„ã‚ˆã†ã«ï¼‰
            let didStart = await player.waitForPlaybackToStart(timeout: 10.0)
            if didStart, self.currentPlayRequestId == requestId {
                preparingCardId = nil
                isPlaying = true
                playingCardId = card.id

            let progressTask = Task { @MainActor in
                let startTime = Date()
                while !Task.isCancelled && self.playingCardId == card.id {
                    let elapsed = Date().timeIntervalSince(startTime)
                        // å†ç”Ÿä¸­ã¯ã€Œã»ã¼æœ€å¾Œã€ã¾ã§é€²ã‚ã€å®Œäº†æ™‚ã«1.0ã¸åˆ°é”ã•ã›ã‚‹
                        self.playbackProgress = min(elapsed / estimatedDuration, 0.999)
                    try? await Task.sleep(nanoseconds: 50_000_000)
                }
            }

                _ = try await speakTask.value
            progressTask.cancel()
                // âœ… ã“ã“ãŒä¸€æ°—ã«é£›ã¶ã¨ã€Œå¾ŒåŠã§åŠ é€Ÿã€ã«è¦‹ãˆã‚‹ã®ã§ã€ç·šå½¢ã§1.0ã¸åˆ°é”ã•ã›ã‚‹
                withAnimation(.linear(duration: 0.12)) {
            playbackProgress = 1.0
                }
                shouldDelayFinalizeUI = true
            } else {
                _ = try await speakTask.value
            }
        } catch {
            print("âŒ playPhrase[\(requestId)]: å†ç”Ÿã‚¨ãƒ©ãƒ¼ - text=\"\(card.text)\", error=\(error.localizedDescription)")
        }
    }

    // éŸ³å£°å…¥åŠ›ï¼ˆå³æ™‚ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º â†’ è¿½åŠ ã¸ï¼‰
    func startVoiceInput(clearExistingText: Bool) {
        if isRecording { return }
        analytics.log(.voiceInputStart)
        Task { @MainActor in
            self.voiceInputError = nil
            print("ğŸ¤ ParentPhrasesController: startVoiceInput()")

            guard await self.ensureVoiceInputPermissions() else {
                self.isVoiceInputPresented = true
                self.isRecording = false
                return
            }
            guard self.speech.isAvailable else {
                self.voiceInputError = "éŸ³å£°èªè­˜ãŒç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
                print("âš ï¸ ParentPhrasesController: SpeechRecognizer not available")
                self.isVoiceInputPresented = true
                self.isRecording = false
                return
            }

            // å†ç”Ÿä¸­ãªã‚‰æ­¢ã‚ã‚‹ï¼ˆãƒã‚¤ã‚¯å…¥åŠ›ã¨å¹²æ¸‰ã—ã‚„ã™ã„ï¼‰
            if self.isPlaying || self.preparingCardId != nil {
                self.currentPlayRequestId = nil
                self.playQueueTask?.cancel()
                self.playQueueTask = nil
                self.ttsEngine.cancelCurrentPlayback(reason: "voice_input_started")
                self.isPlaying = false
                self.playingCardId = nil
                self.preparingCardId = nil
                self.playbackProgress = 0.0
            }

            self.isVoiceInputPresented = true
            self.voiceInputLastBufferAt = nil
            if clearExistingText {
                self.voiceInputText = ""
                self.voiceInputPrefixText = ""
            } else {
                self.voiceInputPrefixText = self.voiceInputText.trimmingCharacters(in: .whitespacesAndNewlines)
            }

            // requestã¯ä½¿ã„å›ã—ã—ãªã„ï¼ˆã‚¿ã‚¹ã‚¯è·¨ãã§å£Šã‚Œã‚„ã™ã„ï¼‰
            self.speechRequest?.endAudio()
            self.speechRequest = nil
            let request = SFSpeechAudioBufferRecognitionRequest()
            request.shouldReportPartialResults = true
            self.speechRequest = request

            // âœ… ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ã«å½±éŸ¿ã‚’å‡ºã•ãªã„ãŸã‚ã€tapã‚’å¢—ã‚„ã•ãš â€œæ—¢å­˜ã®MicrophoneCaptureâ€ ã®å…¥åŠ›ã‚’è³¼èª­ã™ã‚‹
            self.voiceInputRMS = -60.0
            self.micBufferObserver.map(NotificationCenter.default.removeObserver)
            self.micRMSObserver.map(NotificationCenter.default.removeObserver)
            self.micCapture?.stop()
            self.micCapture = nil
            self.voiceInputFallbackTask?.cancel()
            self.voiceInputFallbackTask = nil
            self.micBufferObserver = NotificationCenter.default.addObserver(
                forName: MicrophoneCapture.Notifications.inputBuffer,
                object: nil,
                queue: nil
            ) { [weak self] note in
                guard let buffer = note.object as? AVAudioPCMBuffer else { return }
                Task { @MainActor [weak self] in
                    guard let self else { return }
                    guard self.isVoiceInputPresented else { return }
                    self.voiceInputLastBufferAt = Date()
                    self.speechRequest?.append(buffer)
                }
            }
            self.micRMSObserver = NotificationCenter.default.addObserver(
                forName: MicrophoneCapture.Notifications.rms,
                object: nil,
                queue: nil
            ) { [weak self] note in
                guard let rms = note.object as? Double else { return }
                Task { @MainActor [weak self] in
                    guard let self else { return }
                    guard self.isVoiceInputPresented else { return }
                    self.voiceInputLastBufferAt = Date()
                    self.voiceInputRMS = rms
                }
            }

            // âœ… 0.6så¾…ã£ã¦ã‚‚å…¥åŠ›ãŒæ¥ãªã„å ´åˆã¯ã€Œå˜ç‹¬éŒ²éŸ³ã€ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            // - ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ãŒå‹•ã„ã¦ã„ã‚‹å ´åˆã¯é€šçŸ¥çµŒè·¯ãŒæ¥ã‚‹ã¯ãšãªã®ã§ã€å½±éŸ¿ã‚¼ãƒ­ã®ã¾ã¾å‹•ã
            // - ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ãŒå‹•ã„ã¦ã„ãªã„å ´åˆã¯å˜ç‹¬ã‚¨ãƒ³ã‚¸ãƒ³ã§éŒ²éŸ³é–‹å§‹ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã™ã‚‹
            self.voiceInputFallbackTask = Task { @MainActor [weak self] in
                guard let self else { return }
                try? await Task.sleep(nanoseconds: 600_000_000)
                guard self.isVoiceInputPresented else { return }
                guard self.voiceInputLastBufferAt == nil else { return }

                // é€šçŸ¥è³¼èª­ã‚’æ­¢ã‚ã€å˜ç‹¬ã‚­ãƒ£ãƒ—ãƒãƒ£ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ï¼ˆäºŒé‡appendé˜²æ­¢ï¼‰
                self.micBufferObserver.map(NotificationCenter.default.removeObserver)
                self.micBufferObserver = nil
                self.micRMSObserver.map(NotificationCenter.default.removeObserver)
                self.micRMSObserver = nil

                do {
                    try self.startStandaloneVoiceCapture()
                } catch {
                    self.voiceInputError = "éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼/ä¼šè©±ã‚’åœæ­¢ã—ã¦ã‹ã‚‰ã€ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
                    print("âš ï¸ ParentPhrasesController: standalone mic start failed - \(error.localizedDescription)")
                }
            }

            self.speechTask?.cancel()
            self.speechTask = self.speech.startTask(
                request: request,
                onResult: { [weak self] text, isFinal in
                    Task { @MainActor in
                        guard let self else { return }
                        guard self.isVoiceInputPresented else { return }
                        let base = self.voiceInputPrefixText
                        let t = text.trimmingCharacters(in: .whitespacesAndNewlines)
                        if base.isEmpty {
                            self.voiceInputText = t
                        } else if t.isEmpty {
                            self.voiceInputText = base
                        } else {
                            self.voiceInputText = base + " " + t
                        }
                        if isFinal {
                            self.stopVoiceInput(keepPanel: true)
                        }
                    }
                },
                onError: { [weak self] error in
                    Task { @MainActor in
                        guard let self else { return }
                        // ã‚­ãƒ£ãƒ³ã‚»ãƒ«/ç„¡éŸ³ç³»ã¯é»™ã£ã¦æ­¢ã‚ã‚‹
                        let ns = error as NSError
                        let msg = ns.localizedDescription.lowercased()
                        let benign = msg.contains("canceled") || msg.contains("no speech")
                        if !benign {
                            self.voiceInputError = error.localizedDescription
                            print("âš ï¸ ParentPhrasesController: voice input error - \(error.localizedDescription)")
                        }
                        self.stopVoiceInput(keepPanel: true)
                    }
                }
            )

            self.isRecording = true
            print("ğŸ¤ ParentPhrasesController: voice input running")
        }
    }

    // toggle/cancel/stop/tap helpers are implemented in ParentPhrasesController+VoiceInput.swift

    func saveCard(_ card: PhraseCard) {
        let isNew = !cards.contains(where: { $0.id == card.id })
        Task {
            try? await repository.upsert(card)
            await loadCards()
            editCard = nil
            if !card.category.isBuiltin {
                addCustomCategory(card.category.name)
            }
            analytics.log(.phraseCardSave(category: card.category.name, isNew: isNew))
            print("âœ… ã‚«ãƒ¼ãƒ‰ä¿å­˜å®Œäº†: \(card.text)")
        }
    }

    func deleteCard(_ card: PhraseCard) {
        Task {
            try? await repository.delete(id: card.id)
            await loadCards()
            analytics.log(.phraseCardDelete(category: card.category.name))
            print("ğŸ—‘ï¸ ã‚«ãƒ¼ãƒ‰å‰Šé™¤å®Œäº†: \(card.text)")
        }
    }
}
