import AVFoundation

/// âœ… ãƒã‚¤ã‚¯å…¥åŠ›ã‚­ãƒ£ãƒ—ãƒãƒ£ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›
/// 
/// ## é‡è¦ãªè¨­å®šãƒã‚¤ãƒ³ãƒˆ
/// 1. **å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: 24kHz/mono/PCM16LEï¼ˆOpenAI Realtime APIã®è¦æ±‚ä»•æ§˜ï¼‰
/// 2. **ãƒãƒƒãƒé€ä¿¡**: 200msã”ã¨ã«ã¾ã¨ã‚ã¦é€ä¿¡ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŠ¹ç‡ã¨VADã®ç²¾åº¦å‘ä¸Šï¼‰
/// 3. **ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›**: AVAudioConverterã§ç¢ºå®Ÿã«24kHz/mono/PCM16ã«å¤‰æ›
/// 
/// ## å¤‰æ›ãƒ•ãƒ­ãƒ¼
/// - å…¥åŠ›: ãƒ‡ãƒã‚¤ã‚¹ä¾å­˜ï¼ˆé€šå¸¸48kHz/mono/Float32ã€AECé©ç”¨å¾Œï¼‰
/// - ã‚¨ãƒ³ã‚¸ãƒ³å†…: 48kHz/monoã§å‡¦ç†ï¼ˆAECæœ€é©åŒ–ã®ãŸã‚ï¼‰
/// - é€ä¿¡æ™‚å¤‰æ›: AVAudioConverterã§24kHz/mono/PCM16LEã«å¤‰æ›ï¼ˆã‚µãƒ¼ãƒé€ä¿¡ã®ç›´å‰ï¼‰
/// - ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°: 200msåˆ†ã‚’ã¾ã¨ã‚ã¦é€ä¿¡
/// - å‡ºåŠ›: 24kHz/mono/PCM16LEå½¢å¼ã®AVAudioPCMBuffer
/// 
/// ## AECå¯¾ç­–
/// - **ã‚¨ãƒ³ã‚¸ãƒ³å†…ã¯48kHz/monoã§çµ±ä¸€**: AECã¯48kHz/ãƒ¢ãƒã®ãƒ‘ã‚¹ã§æœ€ã‚‚å®‰å®š
/// - **å†ç”Ÿä¸­ã®ãƒã‚¤ã‚¯é€ä¿¡ã‚²ãƒ¼ãƒˆ**: AIå†ç”Ÿä¸­ã¯ãƒã‚¤ã‚¯å…¥åŠ›ã‚’ã‚µãƒ¼ãƒã«é€ä¿¡ã—ãªã„ï¼ˆãƒãƒ¼ãƒ•ãƒ‡ãƒ¥ãƒ—ãƒ¬ãƒƒã‚¯ã‚¹ï¼‰
/// - **ãƒãƒ¼ã‚¸ã‚¤ãƒ³æ¤œå‡º**: ãƒãƒ¼ã‚¸ã‚¤ãƒ³æ¤œå‡ºæ™‚ã®ã¿é€ä¿¡ã‚’å†é–‹
public final class MicrophoneCapture {
  private let engine = AVAudioEngine()
  private let outFormat: AVAudioFormat
  private let converter: AVAudioConverter
  private let onPCM: (AVAudioPCMBuffer) -> Void
  private var running = false
  
  // âœ… ãƒãƒƒãƒé€ä¿¡ç”¨ï¼š20msÃ—10ï¼ˆ=200msï¼‰ã‚’ã¾ã¨ã‚ã¦é€ä¿¡
  private var audioBuffer: Data = Data()
  private let batchDurationMs: Double = 200.0  // 200msãƒãƒƒãƒ
  private var lastFlushTime: Date = Date()
  private let flushQueue = DispatchQueue(label: "com.asobo.audio.flush")
  
  // âœ… AECå¯¾ç­–ï¼šå†ç”Ÿä¸­ã‚²ãƒ¼ãƒˆåˆ¶å¾¡
  private var isAIPlayingAudio: Bool = false
  private var userBargeIn: Bool = false
  private var outputMonitor: OutputMonitor?
  private let rmsMarginDb: Double = 12.0  // å…¥åŠ›RMSãŒå‡ºåŠ›RMS+12dBä»¥ä¸Šã§ãƒãƒ¼ã‚¸ã‚¤ãƒ³
  private let playbackQuietDbThreshold: Double = -35.0  // å‡ºåŠ›ãŒ-35dBFSä»¥ä¸‹ã§ãƒãƒ¼ã‚¸ã‚¤ãƒ³è¨±å¯
  private var recentInputRMS: [Double] = []  // ç›´è¿‘200msã®å…¥åŠ›RMS
  private let rmsWindowSize: Int = 10  // 10ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆç´„200msï¼‰

  public init?(onPCM: @escaping (AVAudioPCMBuffer) -> Void, outputMonitor: OutputMonitor? = nil) {
    self.onPCM = onPCM
    self.outputMonitor = outputMonitor
    let inputNode = engine.inputNode
    let inFormat  = inputNode.inputFormat(forBus: 0)
    guard
      let out = AVAudioFormat(commonFormat: .pcmFormatInt16,
                              sampleRate: 24_000,  // âœ… 24kHzã«å¤‰æ›´ï¼ˆOpenAI Realtime APIã®è¦æ±‚ä»•æ§˜ã«åˆã‚ã›ã‚‹ï¼‰
                              channels: 1,
                              interleaved: true),
      let conv = AVAudioConverter(from: inFormat, to: out)
    else { return nil }
    self.outFormat = out
    self.converter = conv
  }
  
  /// âœ… AIå†ç”ŸçŠ¶æ…‹ã‚’è¨­å®š
  public func setAIPlayingAudio(_ isPlaying: Bool) {
    isAIPlayingAudio = isPlaying
    if !isPlaying {
      // å†ç”Ÿçµ‚äº†æ™‚ã«ãƒãƒ¼ã‚¸ã‚¤ãƒ³ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
      userBargeIn = false
      recentInputRMS.removeAll()
    }
  }
  
  /// âœ… RMSè¨ˆç®—ï¼ˆdBFSï¼‰
  private func calculateRMS(from buffer: AVAudioPCMBuffer) -> Double {
    guard let channelData = buffer.floatChannelData else { return -60.0 }
    let channelCount = Int(buffer.format.channelCount)
    let frameLength = Int(buffer.frameLength)
    
    var sum: Float = 0.0
    for ch in 0..<channelCount {
      let channel = channelData[ch]
      for i in 0..<frameLength {
        let sample = channel[i]
        sum += sample * sample
      }
    }
    
    let mean = sum / Float(frameLength * channelCount)
    let rms = sqrt(mean)
    
    // dBFSã«å¤‰æ›
    if rms < 1e-10 {
      return -60.0
    }
    return 20.0 * log10(Double(rms))
  }
  
  /// âœ… ãƒãƒ¼ã‚¸ã‚¤ãƒ³åˆ¤å®š
  private func checkBargeIn(inputRMS: Double, outputRMS: Double) -> Bool {
    // ç›´è¿‘200msã®å…¥åŠ›RMSã‚’è¨˜éŒ²
    recentInputRMS.append(inputRMS)
    if recentInputRMS.count > rmsWindowSize {
      recentInputRMS.removeFirst()
    }
    
    // ç›´è¿‘200msã®å¹³å‡å…¥åŠ›RMS
    let avgInputRMS = recentInputRMS.reduce(0, +) / Double(recentInputRMS.count)
    
    // ãƒãƒ¼ã‚¸ã‚¤ãƒ³æ¡ä»¶ï¼š
    // 1. å…¥åŠ›RMSãŒå‡ºåŠ›RMS+ãƒãƒ¼ã‚¸ãƒ³ä»¥ä¸Š
    // 2. å‡ºåŠ›RMSãŒä¸€å®šä»¥ä¸‹ï¼ˆã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãŒé³´ã£ã¦ã„ãªã„ï¼‰
    let condition1 = avgInputRMS > (outputRMS + rmsMarginDb)
    let condition2 = outputRMS < playbackQuietDbThreshold
    
    return condition1 && condition2
  }

  public func start() throws {
    guard !running else { return }
    let inputNode = engine.inputNode
    let inFormat  = inputNode.inputFormat(forBus: 0)

    // âœ… å…¥åŠ›å´ã® tap ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã¯ã€Œ20ms ç›¸å½“ã€ï¼ˆå†…éƒ¨ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ç”¨ï¼‰
    let framesPer20ms = AVAudioFrameCount(inFormat.sampleRate * 0.02)
    audioBuffer.removeAll()
    lastFlushTime = Date()

    inputNode.installTap(onBus: 0, bufferSize: framesPer20ms, format: inFormat) { [weak self] buffer, _ in
      guard let self else { return }
      
      // âœ… AECå¯¾ç­–ï¼šå†ç”Ÿä¸­ã‚²ãƒ¼ãƒˆåˆ¶å¾¡
      let inputRMS = self.calculateRMS(from: buffer)
      let outputRMS = self.outputMonitor?.currentRMS ?? -60.0
      
      if self.isAIPlayingAudio && !self.userBargeIn {
        // ãƒãƒ¼ã‚¸ã‚¤ãƒ³åˆ¤å®š
        if self.checkBargeIn(inputRMS: inputRMS, outputRMS: outputRMS) {
          self.userBargeIn = true
          print("ğŸ¤ MicrophoneCapture: ãƒãƒ¼ã‚¸ã‚¤ãƒ³æ¤œå‡º - inputRMS: \(String(format: "%.1f", inputRMS))dB, outputRMS: \(String(format: "%.1f", outputRMS))dB")
          // ãƒãƒ¼ã‚¸ã‚¤ãƒ³æˆç«‹æ™‚ã¯é€ä¿¡ã‚’è¨±å¯ï¼ˆresponse.cancelã¯ä¸Šä½ã§é€ä¿¡ï¼‰
        } else {
          // å†ç”Ÿä¸­ã§ãƒãƒ¼ã‚¸ã‚¤ãƒ³æœªæ¤œå‡ºï¼šé€ä¿¡ã—ãªã„ï¼ˆãƒ«ãƒ¼ãƒ—æ ¹çµ¶ï¼‰
          return
        }
      }

      // âœ… é€ã‚‹å‰ã«24kHz mono PCM16LEã¸å¿…ãšãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒ«ï¼†é‡å­åŒ–
      // âœ… AVAudioEngineã®ã‚¿ãƒƒãƒ—ã¯Float32ãŒå¤šã„ã€‚å¸¸ã«AVAudioConverterã§24kHz/mono/Int16ã«å¤‰æ›
      // âœ… å¤‰æ›ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆé€ä¿¡ç”¨ï¼‰ï¼š24kHz/mono/PCM16LE
      // âœ… å…¥åŠ›ãƒãƒƒãƒ•ã‚¡ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰é€ä¿¡ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¸ã®å¤‰æ›ã‚’ç¢ºå®Ÿã«å®Ÿè¡Œ
      let ratio = self.outFormat.sampleRate / buffer.format.sampleRate
      let framesOut = AVAudioFrameCount(Double(buffer.frameLength) * ratio + 8)  // ä½™è£•ã‚’æŒãŸã›ã‚‹
      guard let outBuf = AVAudioPCMBuffer(pcmFormat: self.outFormat, frameCapacity: framesOut) else { return }
      outBuf.frameLength = framesOut

      var error: NSError?
      let status = self.converter.convert(to: outBuf, error: &error) { inCount, outStatus in
        outStatus.pointee = .haveData
        return buffer
      }

      if (status == .haveData || status == .endOfStream), outBuf.frameLength > 0 {
        // âœ… ãƒãƒƒãƒ•ã‚¡ã«è“„ç©ï¼ˆ20msã”ã¨ã«è¿½åŠ ï¼‰
        // âœ… å¿…ãšint16ChannelDataã‹ã‚‰å–å¾—ï¼ˆPCM16LEå½¢å¼ï¼‰
        guard let ch0 = outBuf.int16ChannelData else { return }
        let byteCount = Int(outBuf.frameLength) * MemoryLayout<Int16>.size
        let ptr = ch0.pointee
        
        self.flushQueue.async {
          // âœ… éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ï¼ˆPCM16LEå½¢å¼ã®Dataï¼‰
          self.audioBuffer.append(Data(bytes: ptr, count: byteCount))
          
          // âœ… 200msçµŒéã—ãŸã‚‰ãƒãƒƒãƒé€ä¿¡
          let now = Date()
          let elapsed = now.timeIntervalSince(self.lastFlushTime) * 1000.0  // ãƒŸãƒªç§’
          if elapsed >= self.batchDurationMs && !self.audioBuffer.isEmpty {
            let batchData = self.audioBuffer
            self.audioBuffer.removeAll()
            self.lastFlushTime = now
            
            // âœ… ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’AVAudioPCMBufferã¨ã—ã¦å†æ§‹ç¯‰
            let batchFrames = batchData.count / MemoryLayout<Int16>.size
            guard batchFrames > 0,
                  let batchBuf = AVAudioPCMBuffer(pcmFormat: self.outFormat, frameCapacity: AVAudioFrameCount(batchFrames)) else {
              return
            }
            batchBuf.frameLength = AVAudioFrameCount(batchFrames)
            
            if let batchCh0 = batchBuf.int16ChannelData {
              batchData.withUnsafeBytes { rawPtr in
                guard let basePtr = rawPtr.baseAddress?.assumingMemoryBound(to: Int16.self) else { return }
                batchCh0.pointee.initialize(from: basePtr, count: batchFrames)
              }
              self.onPCM(batchBuf)  // â† 200msãƒãƒƒãƒã§ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
            }
          }
        }
      }
    }

    try engine.start()
    running = true
  }

  public func stop() {
    guard running else { return }
    // âœ… æ®‹ã‚Šã®ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
    flushQueue.sync {
      if !audioBuffer.isEmpty {
        let batchData = audioBuffer
        audioBuffer.removeAll()
        
        let batchFrames = batchData.count / MemoryLayout<Int16>.size
        if batchFrames > 0, let batchBuf = AVAudioPCMBuffer(pcmFormat: outFormat, frameCapacity: AVAudioFrameCount(batchFrames)) {
          batchBuf.frameLength = AVAudioFrameCount(batchFrames)
          if let batchCh0 = batchBuf.int16ChannelData {
            batchData.withUnsafeBytes { rawPtr in
              guard let basePtr = rawPtr.baseAddress?.assumingMemoryBound(to: Int16.self) else { return }
              batchCh0.pointee.initialize(from: basePtr, count: batchFrames)
            }
            onPCM(batchBuf)
          }
        }
      }
    }
    engine.inputNode.removeTap(onBus: 0)
    engine.stop()
    running = false
  }
}
